{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AftvNA5VMemJ"
      },
      "source": [
        "# Federated Learning for Energy Meter Time Series Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ZrGitA_KnRO0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4dcb0580-1550-4290-a039-ec89c21c9eb2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.3/68.3 MB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.5/103.5 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.7/98.7 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m558.5/558.5 kB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m52.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m255.8/255.8 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m238.9/238.9 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m359.4/359.4 kB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.7/126.7 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m532.6/532.6 kB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.9/39.9 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m36.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m42.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m72.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m69.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m146.0/146.0 kB\u001b[0m \u001b[31m599.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for farmhashpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for jax (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for sqlalchemy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "arviz 0.15.1 requires scipy>=1.8.0, but you have scipy 1.7.3 which is incompatible.\n",
            "chex 0.1.7 requires jax>=0.4.6, but you have jax 0.3.15 which is incompatible.\n",
            "flax 0.6.9 requires jax>=0.4.2, but you have jax 0.3.15 which is incompatible.\n",
            "google-colab 1.0.0 requires portpicker==1.3.9, but you have portpicker 1.5.2 which is incompatible.\n",
            "orbax-checkpoint 0.2.1 requires jax>=0.4.8, but you have jax 0.3.15 which is incompatible.\n",
            "pymc 5.1.2 requires cachetools>=4.2.1, but you have cachetools 3.1.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "#@test {\"skip\": true}\n",
        "\n",
        "!pip install --quiet --upgrade tensorflow-federated"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QLyJIaLlERJ8"
      },
      "outputs": [],
      "source": [
        "%load_ext tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "8BKyHkMxKHfV",
        "outputId": "22745797-0e6c-432a-da04-7a334ca4a203",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "b'Hello, World!'"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import collections\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_federated as tff\n",
        "\n",
        "np.random.seed(0)\n",
        "\n",
        "tff.federated_computation(lambda: 'Hello, World!')()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "OOWyvDAqBl2L",
        "outputId": "d8d5f200-2ced-48a0-cfb2-8c8ad73cf33c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = pd.read_csv('/content/drive/MyDrive/LAB3-20221109T160610Z-001/LCL-FullData/Cluster14data.csv')"
      ],
      "metadata": {
        "id": "ix-28z9-Bhb8"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dividing the two year data into 24 parts (each 1 month data)\n",
        "data['DateTime'] = pd.to_datetime(data['DateTime'])"
      ],
      "metadata": {
        "id": "Ihxg-Bqu-KFk"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "qVAWFXCpb5wd",
        "outputId": "a295f216-89f6-4b2a-d0a5-87193ddc4647"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             LCLid stdorToU            DateTime  KWH/hh  cluster\n",
              "0        MAC000025      Std 2011-12-07 11:00:00   0.171       14\n",
              "1        MAC000025      Std 2011-12-07 11:30:00   0.057       14\n",
              "2        MAC000025      Std 2011-12-07 12:00:00   0.057       14\n",
              "3        MAC000025      Std 2011-12-07 12:30:00   0.072       14\n",
              "4        MAC000025      Std 2011-12-07 13:00:00   0.000       14\n",
              "...            ...      ...                 ...     ...      ...\n",
              "8412427  MAC005529      ToU 2014-02-27 22:30:00   0.414       14\n",
              "8412428  MAC005529      ToU 2014-02-27 23:00:00   0.404       14\n",
              "8412429  MAC005529      ToU 2014-02-27 23:30:00   0.120       14\n",
              "8412430  MAC005529      ToU 2014-02-28 00:00:00   0.009       14\n",
              "8412431  MAC005529      ToU 2014-02-28 00:00:00   0.009       14\n",
              "\n",
              "[8412432 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9ed41fee-b37a-4588-bc2a-db4db5d836df\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>LCLid</th>\n",
              "      <th>stdorToU</th>\n",
              "      <th>DateTime</th>\n",
              "      <th>KWH/hh</th>\n",
              "      <th>cluster</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>MAC000025</td>\n",
              "      <td>Std</td>\n",
              "      <td>2011-12-07 11:00:00</td>\n",
              "      <td>0.171</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>MAC000025</td>\n",
              "      <td>Std</td>\n",
              "      <td>2011-12-07 11:30:00</td>\n",
              "      <td>0.057</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>MAC000025</td>\n",
              "      <td>Std</td>\n",
              "      <td>2011-12-07 12:00:00</td>\n",
              "      <td>0.057</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>MAC000025</td>\n",
              "      <td>Std</td>\n",
              "      <td>2011-12-07 12:30:00</td>\n",
              "      <td>0.072</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>MAC000025</td>\n",
              "      <td>Std</td>\n",
              "      <td>2011-12-07 13:00:00</td>\n",
              "      <td>0.000</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8412427</th>\n",
              "      <td>MAC005529</td>\n",
              "      <td>ToU</td>\n",
              "      <td>2014-02-27 22:30:00</td>\n",
              "      <td>0.414</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8412428</th>\n",
              "      <td>MAC005529</td>\n",
              "      <td>ToU</td>\n",
              "      <td>2014-02-27 23:00:00</td>\n",
              "      <td>0.404</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8412429</th>\n",
              "      <td>MAC005529</td>\n",
              "      <td>ToU</td>\n",
              "      <td>2014-02-27 23:30:00</td>\n",
              "      <td>0.120</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8412430</th>\n",
              "      <td>MAC005529</td>\n",
              "      <td>ToU</td>\n",
              "      <td>2014-02-28 00:00:00</td>\n",
              "      <td>0.009</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8412431</th>\n",
              "      <td>MAC005529</td>\n",
              "      <td>ToU</td>\n",
              "      <td>2014-02-28 00:00:00</td>\n",
              "      <td>0.009</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8412432 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9ed41fee-b37a-4588-bc2a-db4db5d836df')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9ed41fee-b37a-4588-bc2a-db4db5d836df button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9ed41fee-b37a-4588-bc2a-db4db5d836df');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter the DataFrame to include readings from Jan 01, 2012, to Jan 31, 2012\n",
        "start_date1 = pd.to_datetime('2012-01-01')\n",
        "end_date1 = pd.to_datetime('2012-01-31')\n",
        "filtered_data1 = data[(data['DateTime'] >= start_date1) & (data['DateTime'] <= end_date1)]\n",
        "\n",
        "# Filter the DataFrame to include readings from Feb 01, 2012, to Feb 29, 2012\n",
        "start_date2 = pd.to_datetime('2012-02-01')\n",
        "end_date2 = pd.to_datetime('2012-02-29')\n",
        "filtered_data2 = data[(data['DateTime'] >= start_date2) & (data['DateTime'] <= end_date2)]\n",
        "\n",
        "# Filter the DataFrame to include readings from March 01, 2012, to March 31, 2012\n",
        "start_date3 = pd.to_datetime('2012-03-01')\n",
        "end_date3 = pd.to_datetime('2012-03-31')\n",
        "filtered_data3 = data[(data['DateTime'] >= start_date3) & (data['DateTime'] <= end_date3)]\n",
        "\n",
        "# Filter the DataFrame to include readings from April 01, 2012, to Apr 30, 2012\n",
        "start_date4 = pd.to_datetime('2012-04-01')\n",
        "end_date4 = pd.to_datetime('2012-04-30')\n",
        "filtered_data4 = data[(data['DateTime'] >= start_date4) & (data['DateTime'] <= end_date4)]\n",
        "\n",
        "# Filter the DataFrame to include readings from May 01, 2012, to May 31, 2012\n",
        "start_date5 = pd.to_datetime('2012-05-01')\n",
        "end_date5 = pd.to_datetime('2012-05-31')\n",
        "filtered_data5 = data[(data['DateTime'] >= start_date5) & (data['DateTime'] <= end_date5)]\n",
        "\n",
        "# Filter the DataFrame to include readings from Jun 01, 2012, to Jun 30, 2012\n",
        "start_date6 = pd.to_datetime('2012-06-01')\n",
        "end_date6 = pd.to_datetime('2012-06-30')\n",
        "filtered_data6 = data[(data['DateTime'] >= start_date6) & (data['DateTime'] <= end_date6)]\n",
        "\n",
        "# Filter the DataFrame to include readings from Jul 01, 2012, to Jul 31, 2012\n",
        "start_date7 = pd.to_datetime('2012-07-01')\n",
        "end_date7 = pd.to_datetime('2012-07-31')\n",
        "filtered_data7 = data[(data['DateTime'] >= start_date7) & (data['DateTime'] <= end_date7)]\n",
        "\n",
        "# Filter the DataFrame to include readings from Aug 01, 2012, to Aug 31, 2012\n",
        "start_date8 = pd.to_datetime('2012-08-01')\n",
        "end_date8 = pd.to_datetime('2012-08-31')\n",
        "filtered_data8 = data[(data['DateTime'] >= start_date8) & (data['DateTime'] <= end_date8)]\n",
        "\n",
        "# Filter the DataFrame to include readings from Sep 01, 2012, to Sep 30, 2012\n",
        "start_date9 = pd.to_datetime('2012-09-01')\n",
        "end_date9 = pd.to_datetime('2012-09-30')\n",
        "filtered_data9 = data[(data['DateTime'] >= start_date9) & (data['DateTime'] <= end_date9)]\n",
        "\n",
        "# Filter the DataFrame to include readings from Oct 01, 2012, to Oct 31, 2012\n",
        "start_date10 = pd.to_datetime('2012-10-01')\n",
        "end_date10 = pd.to_datetime('2012-10-31')\n",
        "filtered_data10 = data[(data['DateTime'] >= start_date10) & (data['DateTime'] <= end_date10)]\n",
        "\n",
        "# Filter the DataFrame to include readings from Nov 01, 2012, to Nov 30, 2012\n",
        "start_date11 = pd.to_datetime('2012-11-01')\n",
        "end_date11 = pd.to_datetime('2012-11-30')\n",
        "filtered_data11 = data[(data['DateTime'] >= start_date11) & (data['DateTime'] <= end_date11)]\n",
        "\n",
        "# Filter the DataFrame to include readings from Dec 01, 2012, to Dec 31, 2012\n",
        "start_date12 = pd.to_datetime('2012-12-01')\n",
        "end_date12 = pd.to_datetime('2012-12-31')\n",
        "filtered_data12 = data[(data['DateTime'] >= start_date12) & (data['DateTime'] <= end_date12)]\n",
        "\n",
        "\n",
        "filtered_data1\n",
        "filtered_data2\n",
        "filtered_data3\n",
        "filtered_data4\n",
        "filtered_data5\n",
        "filtered_data6\n",
        "filtered_data7\n",
        "filtered_data8\n",
        "filtered_data9\n",
        "filtered_data10\n",
        "filtered_data11\n",
        "filtered_data12\n"
      ],
      "metadata": {
        "id": "zqKS4fadBuNM",
        "outputId": "3fefc864-3282-46bd-a12d-7bfbca21d98e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             LCLid stdorToU            DateTime  KWH/hh  cluster\n",
              "17263    MAC000025      Std 2012-12-01 00:00:00   0.005       14\n",
              "17264    MAC000025      Std 2012-12-01 00:30:00   0.014       14\n",
              "17265    MAC000025      Std 2012-12-01 01:00:00   0.015       14\n",
              "17266    MAC000025      Std 2012-12-01 01:30:00   0.005       14\n",
              "17267    MAC000025      Std 2012-12-01 02:00:00   0.024       14\n",
              "...            ...      ...                 ...     ...      ...\n",
              "8392065  MAC005529      ToU 2012-12-30 22:00:00   0.229       14\n",
              "8392066  MAC005529      ToU 2012-12-30 22:30:00   0.317       14\n",
              "8392067  MAC005529      ToU 2012-12-30 23:00:00   0.300       14\n",
              "8392068  MAC005529      ToU 2012-12-30 23:30:00   0.295       14\n",
              "8392069  MAC005529      ToU 2012-12-31 00:00:00   0.326       14\n",
              "\n",
              "[404413 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-82805253-f3a8-4af6-be8d-2ad558ba33be\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>LCLid</th>\n",
              "      <th>stdorToU</th>\n",
              "      <th>DateTime</th>\n",
              "      <th>KWH/hh</th>\n",
              "      <th>cluster</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>17263</th>\n",
              "      <td>MAC000025</td>\n",
              "      <td>Std</td>\n",
              "      <td>2012-12-01 00:00:00</td>\n",
              "      <td>0.005</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17264</th>\n",
              "      <td>MAC000025</td>\n",
              "      <td>Std</td>\n",
              "      <td>2012-12-01 00:30:00</td>\n",
              "      <td>0.014</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17265</th>\n",
              "      <td>MAC000025</td>\n",
              "      <td>Std</td>\n",
              "      <td>2012-12-01 01:00:00</td>\n",
              "      <td>0.015</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17266</th>\n",
              "      <td>MAC000025</td>\n",
              "      <td>Std</td>\n",
              "      <td>2012-12-01 01:30:00</td>\n",
              "      <td>0.005</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17267</th>\n",
              "      <td>MAC000025</td>\n",
              "      <td>Std</td>\n",
              "      <td>2012-12-01 02:00:00</td>\n",
              "      <td>0.024</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8392065</th>\n",
              "      <td>MAC005529</td>\n",
              "      <td>ToU</td>\n",
              "      <td>2012-12-30 22:00:00</td>\n",
              "      <td>0.229</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8392066</th>\n",
              "      <td>MAC005529</td>\n",
              "      <td>ToU</td>\n",
              "      <td>2012-12-30 22:30:00</td>\n",
              "      <td>0.317</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8392067</th>\n",
              "      <td>MAC005529</td>\n",
              "      <td>ToU</td>\n",
              "      <td>2012-12-30 23:00:00</td>\n",
              "      <td>0.300</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8392068</th>\n",
              "      <td>MAC005529</td>\n",
              "      <td>ToU</td>\n",
              "      <td>2012-12-30 23:30:00</td>\n",
              "      <td>0.295</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8392069</th>\n",
              "      <td>MAC005529</td>\n",
              "      <td>ToU</td>\n",
              "      <td>2012-12-31 00:00:00</td>\n",
              "      <td>0.326</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>404413 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-82805253-f3a8-4af6-be8d-2ad558ba33be')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-82805253-f3a8-4af6-be8d-2ad558ba33be button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-82805253-f3a8-4af6-be8d-2ad558ba33be');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_data_2012 = [filtered_data1, filtered_data2, filtered_data3, filtered_data4, filtered_data5, filtered_data6, filtered_data7, filtered_data8, filtered_data9, filtered_data10, filtered_data11, filtered_data12 ]\n",
        "filtered_data_2012[10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "EMj0ImqgAknl",
        "outputId": "3518c708-4b29-4876-b19a-6b84257c7747"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             LCLid stdorToU            DateTime  KWH/hh  cluster\n",
              "15822    MAC000025      Std 2012-11-01 00:00:00   0.021       14\n",
              "15823    MAC000025      Std 2012-11-01 00:30:00   0.005       14\n",
              "15824    MAC000025      Std 2012-11-01 01:00:00   0.030       14\n",
              "15825    MAC000025      Std 2012-11-01 01:30:00   0.005       14\n",
              "15826    MAC000025      Std 2012-11-01 02:00:00   0.025       14\n",
              "...            ...      ...                 ...     ...      ...\n",
              "8390576  MAC005529      ToU 2012-11-29 22:00:00   0.433       14\n",
              "8390577  MAC005529      ToU 2012-11-29 22:30:00   0.434       14\n",
              "8390578  MAC005529      ToU 2012-11-29 23:00:00   0.414       14\n",
              "8390579  MAC005529      ToU 2012-11-29 23:30:00   0.086       14\n",
              "8390580  MAC005529      ToU 2012-11-30 00:00:00   0.030       14\n",
              "\n",
              "[393020 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-63eb44d0-babf-48f7-a9c4-49c7bda6e5c9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>LCLid</th>\n",
              "      <th>stdorToU</th>\n",
              "      <th>DateTime</th>\n",
              "      <th>KWH/hh</th>\n",
              "      <th>cluster</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>15822</th>\n",
              "      <td>MAC000025</td>\n",
              "      <td>Std</td>\n",
              "      <td>2012-11-01 00:00:00</td>\n",
              "      <td>0.021</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15823</th>\n",
              "      <td>MAC000025</td>\n",
              "      <td>Std</td>\n",
              "      <td>2012-11-01 00:30:00</td>\n",
              "      <td>0.005</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15824</th>\n",
              "      <td>MAC000025</td>\n",
              "      <td>Std</td>\n",
              "      <td>2012-11-01 01:00:00</td>\n",
              "      <td>0.030</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15825</th>\n",
              "      <td>MAC000025</td>\n",
              "      <td>Std</td>\n",
              "      <td>2012-11-01 01:30:00</td>\n",
              "      <td>0.005</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15826</th>\n",
              "      <td>MAC000025</td>\n",
              "      <td>Std</td>\n",
              "      <td>2012-11-01 02:00:00</td>\n",
              "      <td>0.025</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8390576</th>\n",
              "      <td>MAC005529</td>\n",
              "      <td>ToU</td>\n",
              "      <td>2012-11-29 22:00:00</td>\n",
              "      <td>0.433</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8390577</th>\n",
              "      <td>MAC005529</td>\n",
              "      <td>ToU</td>\n",
              "      <td>2012-11-29 22:30:00</td>\n",
              "      <td>0.434</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8390578</th>\n",
              "      <td>MAC005529</td>\n",
              "      <td>ToU</td>\n",
              "      <td>2012-11-29 23:00:00</td>\n",
              "      <td>0.414</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8390579</th>\n",
              "      <td>MAC005529</td>\n",
              "      <td>ToU</td>\n",
              "      <td>2012-11-29 23:30:00</td>\n",
              "      <td>0.086</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8390580</th>\n",
              "      <td>MAC005529</td>\n",
              "      <td>ToU</td>\n",
              "      <td>2012-11-30 00:00:00</td>\n",
              "      <td>0.030</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>393020 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-63eb44d0-babf-48f7-a9c4-49c7bda6e5c9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-63eb44d0-babf-48f7-a9c4-49c7bda6e5c9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-63eb44d0-babf-48f7-a9c4-49c7bda6e5c9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter the DataFrame to include readings from Jan 01, 2013, to Jan 31, 2013\n",
        "start_date13 = pd.to_datetime('2013-01-01')\n",
        "end_date13 = pd.to_datetime('2013-01-31')\n",
        "filtered_data13 = data[(data['DateTime'] >= start_date13) & (data['DateTime'] <= end_date13)]\n",
        "\n",
        "# Filter the DataFrame to include readings from Feb 01, 2013, to Feb 28, 2013\n",
        "start_date14 = pd.to_datetime('2013-02-01')\n",
        "end_date14 = pd.to_datetime('2013-02-28')\n",
        "filtered_data14 = data[(data['DateTime'] >= start_date14) & (data['DateTime'] <= end_date14)]\n",
        "\n",
        "# Filter the DataFrame to include readings from March 01, 2013, to March 31, 2013\n",
        "start_date15 = pd.to_datetime('2013-03-01')\n",
        "end_date15 = pd.to_datetime('2013-03-31')\n",
        "filtered_data15 = data[(data['DateTime'] >= start_date15) & (data['DateTime'] <= end_date15)]\n",
        "\n",
        "# Filter the DataFrame to include readings from April 01, 2013, to Apr 30, 2013\n",
        "start_date16 = pd.to_datetime('2013-04-01')\n",
        "end_date16 = pd.to_datetime('2013-04-30')\n",
        "filtered_data16 = data[(data['DateTime'] >= start_date16) & (data['DateTime'] <= end_date16)]\n",
        "\n",
        "# Filter the DataFrame to include readings from May 01, 2013, to May 31, 2013\n",
        "start_date17 = pd.to_datetime('2013-05-01')\n",
        "end_date17 = pd.to_datetime('2013-05-31')\n",
        "filtered_data17 = data[(data['DateTime'] >= start_date17) & (data['DateTime'] <= end_date17)]\n",
        "\n",
        "# Filter the DataFrame to include readings from Jun 01, 2013, to Jun 30, 2013\n",
        "start_date18 = pd.to_datetime('2013-06-01')\n",
        "end_date18 = pd.to_datetime('2013-06-30')\n",
        "filtered_data18 = data[(data['DateTime'] >= start_date18) & (data['DateTime'] <= end_date18)]\n",
        "\n",
        "# Filter the DataFrame to include readings from Jul 01, 2013, to Jul 31, 2013\n",
        "start_date19 = pd.to_datetime('2013-07-01')\n",
        "end_date19 = pd.to_datetime('2013-07-31')\n",
        "filtered_data19 = data[(data['DateTime'] >= start_date19) & (data['DateTime'] <= end_date19)]\n",
        "\n",
        "# Filter the DataFrame to include readings from Aug 01, 2013, to Aug 31, 2013\n",
        "start_date20 = pd.to_datetime('2013-08-01')\n",
        "end_date20 = pd.to_datetime('2013-08-31')\n",
        "filtered_data20 = data[(data['DateTime'] >= start_date20) & (data['DateTime'] <= end_date20)]\n",
        "\n",
        "# Filter the DataFrame to include readings from Sep 01, 2013, to Sep 30, 2013\n",
        "start_date21 = pd.to_datetime('2013-09-01')\n",
        "end_date21 = pd.to_datetime('2013-09-30')\n",
        "filtered_data21 = data[(data['DateTime'] >= start_date21) & (data['DateTime'] <= end_date21)]\n",
        "\n",
        "# Filter the DataFrame to include readings from Oct 01, 2013, to Oct 31, 2013\n",
        "start_date22 = pd.to_datetime('2013-10-01')\n",
        "end_date22 = pd.to_datetime('2013-10-31')\n",
        "filtered_data22 = data[(data['DateTime'] >= start_date22) & (data['DateTime'] <= end_date22)]\n",
        "\n",
        "# Filter the DataFrame to include readings from Nov 01, 2013, to Nov 30, 2013\n",
        "start_date23 = pd.to_datetime('2013-11-01')\n",
        "end_date23 = pd.to_datetime('2013-11-30')\n",
        "filtered_data23 = data[(data['DateTime'] >= start_date23) & (data['DateTime'] <= end_date23)]\n",
        "\n",
        "# Filter the DataFrame to include readings from Dec 01, 2013, to Dec 31, 2013\n",
        "start_date24 = pd.to_datetime('2013-12-01')\n",
        "end_date24 = pd.to_datetime('2013-12-31')\n",
        "filtered_data24 = data[(data['DateTime'] >= start_date24) & (data['DateTime'] <= end_date24)]\n",
        "\n",
        "\n",
        "filtered_data13\n",
        "filtered_data14\n",
        "filtered_data15\n",
        "filtered_data16\n",
        "filtered_data17\n",
        "filtered_data18\n",
        "filtered_data19\n",
        "filtered_data20\n",
        "filtered_data21\n",
        "filtered_data22\n",
        "filtered_data23\n",
        "filtered_data24"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "x-xM2cdXBFBO",
        "outputId": "8f008f9f-d1d4-40eb-f1f8-8135d0afc452"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             LCLid stdorToU            DateTime  KWH/hh  cluster\n",
              "34788    MAC000025      Std 2013-12-01 00:00:00   0.018       14\n",
              "34789    MAC000025      Std 2013-12-01 00:30:00   0.004       14\n",
              "34790    MAC000025      Std 2013-12-01 01:00:00   0.027       14\n",
              "34791    MAC000025      Std 2013-12-01 01:30:00   0.004       14\n",
              "34792    MAC000025      Std 2013-12-01 02:00:00   0.025       14\n",
              "...            ...      ...                 ...     ...      ...\n",
              "8409594  MAC005529      ToU 2013-12-30 22:00:00   0.391       14\n",
              "8409595  MAC005529      ToU 2013-12-30 22:30:00   0.409       14\n",
              "8409596  MAC005529      ToU 2013-12-30 23:00:00   0.416       14\n",
              "8409597  MAC005529      ToU 2013-12-30 23:30:00   0.401       14\n",
              "8409598  MAC005529      ToU 2013-12-31 00:00:00   0.401       14\n",
              "\n",
              "[358428 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-404728cc-7262-4350-917e-cb66a46e1ce3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>LCLid</th>\n",
              "      <th>stdorToU</th>\n",
              "      <th>DateTime</th>\n",
              "      <th>KWH/hh</th>\n",
              "      <th>cluster</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>34788</th>\n",
              "      <td>MAC000025</td>\n",
              "      <td>Std</td>\n",
              "      <td>2013-12-01 00:00:00</td>\n",
              "      <td>0.018</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34789</th>\n",
              "      <td>MAC000025</td>\n",
              "      <td>Std</td>\n",
              "      <td>2013-12-01 00:30:00</td>\n",
              "      <td>0.004</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34790</th>\n",
              "      <td>MAC000025</td>\n",
              "      <td>Std</td>\n",
              "      <td>2013-12-01 01:00:00</td>\n",
              "      <td>0.027</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34791</th>\n",
              "      <td>MAC000025</td>\n",
              "      <td>Std</td>\n",
              "      <td>2013-12-01 01:30:00</td>\n",
              "      <td>0.004</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34792</th>\n",
              "      <td>MAC000025</td>\n",
              "      <td>Std</td>\n",
              "      <td>2013-12-01 02:00:00</td>\n",
              "      <td>0.025</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8409594</th>\n",
              "      <td>MAC005529</td>\n",
              "      <td>ToU</td>\n",
              "      <td>2013-12-30 22:00:00</td>\n",
              "      <td>0.391</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8409595</th>\n",
              "      <td>MAC005529</td>\n",
              "      <td>ToU</td>\n",
              "      <td>2013-12-30 22:30:00</td>\n",
              "      <td>0.409</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8409596</th>\n",
              "      <td>MAC005529</td>\n",
              "      <td>ToU</td>\n",
              "      <td>2013-12-30 23:00:00</td>\n",
              "      <td>0.416</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8409597</th>\n",
              "      <td>MAC005529</td>\n",
              "      <td>ToU</td>\n",
              "      <td>2013-12-30 23:30:00</td>\n",
              "      <td>0.401</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8409598</th>\n",
              "      <td>MAC005529</td>\n",
              "      <td>ToU</td>\n",
              "      <td>2013-12-31 00:00:00</td>\n",
              "      <td>0.401</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>358428 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-404728cc-7262-4350-917e-cb66a46e1ce3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-404728cc-7262-4350-917e-cb66a46e1ce3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-404728cc-7262-4350-917e-cb66a46e1ce3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_data_2013 = [filtered_data13, filtered_data14, filtered_data15, filtered_data16, filtered_data17, filtered_data18, filtered_data19, filtered_data20, filtered_data21, filtered_data22, filtered_data23, filtered_data24 ]\n",
        "filtered_data_2013[10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "PSMw7fsMCpbO",
        "outputId": "2042ab33-a862-4663-e139-a1475aabf83c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             LCLid stdorToU            DateTime  KWH/hh  cluster\n",
              "33347    MAC000025      Std 2013-11-01 00:00:00   0.021       14\n",
              "33348    MAC000025      Std 2013-11-01 00:30:00   0.005       14\n",
              "33349    MAC000025      Std 2013-11-01 01:00:00   0.025       14\n",
              "33350    MAC000025      Std 2013-11-01 01:30:00   0.013       14\n",
              "33351    MAC000025      Std 2013-11-01 02:00:00   0.005       14\n",
              "...            ...      ...                 ...     ...      ...\n",
              "8408105  MAC005529      ToU 2013-11-29 22:00:00   0.504       14\n",
              "8408106  MAC005529      ToU 2013-11-29 22:30:00   0.353       14\n",
              "8408107  MAC005529      ToU 2013-11-29 23:00:00   0.399       14\n",
              "8408108  MAC005529      ToU 2013-11-29 23:30:00   0.354       14\n",
              "8408109  MAC005529      ToU 2013-11-30 00:00:00   0.242       14\n",
              "\n",
              "[349791 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-447a12b6-dd67-44d5-87f9-9741acc6cf1a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>LCLid</th>\n",
              "      <th>stdorToU</th>\n",
              "      <th>DateTime</th>\n",
              "      <th>KWH/hh</th>\n",
              "      <th>cluster</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>33347</th>\n",
              "      <td>MAC000025</td>\n",
              "      <td>Std</td>\n",
              "      <td>2013-11-01 00:00:00</td>\n",
              "      <td>0.021</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33348</th>\n",
              "      <td>MAC000025</td>\n",
              "      <td>Std</td>\n",
              "      <td>2013-11-01 00:30:00</td>\n",
              "      <td>0.005</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33349</th>\n",
              "      <td>MAC000025</td>\n",
              "      <td>Std</td>\n",
              "      <td>2013-11-01 01:00:00</td>\n",
              "      <td>0.025</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33350</th>\n",
              "      <td>MAC000025</td>\n",
              "      <td>Std</td>\n",
              "      <td>2013-11-01 01:30:00</td>\n",
              "      <td>0.013</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33351</th>\n",
              "      <td>MAC000025</td>\n",
              "      <td>Std</td>\n",
              "      <td>2013-11-01 02:00:00</td>\n",
              "      <td>0.005</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8408105</th>\n",
              "      <td>MAC005529</td>\n",
              "      <td>ToU</td>\n",
              "      <td>2013-11-29 22:00:00</td>\n",
              "      <td>0.504</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8408106</th>\n",
              "      <td>MAC005529</td>\n",
              "      <td>ToU</td>\n",
              "      <td>2013-11-29 22:30:00</td>\n",
              "      <td>0.353</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8408107</th>\n",
              "      <td>MAC005529</td>\n",
              "      <td>ToU</td>\n",
              "      <td>2013-11-29 23:00:00</td>\n",
              "      <td>0.399</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8408108</th>\n",
              "      <td>MAC005529</td>\n",
              "      <td>ToU</td>\n",
              "      <td>2013-11-29 23:30:00</td>\n",
              "      <td>0.354</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8408109</th>\n",
              "      <td>MAC005529</td>\n",
              "      <td>ToU</td>\n",
              "      <td>2013-11-30 00:00:00</td>\n",
              "      <td>0.242</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>349791 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-447a12b6-dd67-44d5-87f9-9741acc6cf1a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-447a12b6-dd67-44d5-87f9-9741acc6cf1a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-447a12b6-dd67-44d5-87f9-9741acc6cf1a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tmfrme = 12\n",
        "lclid_list_2012 = []\n",
        "selected_lclids_2012 = []\n",
        "f_data_2012 = []\n",
        "lclid_list_2013 = []\n",
        "selected_lclids_2013 = []\n",
        "f_data_2013 = []\n",
        "\n",
        "for i in range(tmfrme):\n",
        "    lclid_list_2012.append(filtered_data_2012[i]['LCLid'].unique())\n",
        "    selected_lclids_2012.append(lclid_list_2012[i][:20])\n",
        "    f_data_2012.append(filtered_data_2012[i][filtered_data_2012[i]['LCLid'].isin(selected_lclids_2012[i])])\n",
        "\n",
        "    lclid_list_2013.append(filtered_data_2013[i]['LCLid'].unique())\n",
        "    selected_lclids_2013.append(lclid_list_2013[i][:20])\n",
        "    f_data_2013.append(filtered_data_2013[i][filtered_data_2013[i]['LCLid'].isin(selected_lclids_2013[i])])\n",
        "\n",
        "\n",
        "f_data_2013[10]"
      ],
      "metadata": {
        "id": "vs1SXTGSBuKA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "d61a2d34-afdc-4fdc-921b-c91a00f3a66d"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            LCLid stdorToU            DateTime  KWH/hh  cluster\n",
              "33347   MAC000025      Std 2013-11-01 00:00:00   0.021       14\n",
              "33348   MAC000025      Std 2013-11-01 00:30:00   0.005       14\n",
              "33349   MAC000025      Std 2013-11-01 01:00:00   0.025       14\n",
              "33350   MAC000025      Std 2013-11-01 01:30:00   0.013       14\n",
              "33351   MAC000025      Std 2013-11-01 02:00:00   0.005       14\n",
              "...           ...      ...                 ...     ...      ...\n",
              "720816  MAC000543      Std 2013-11-29 22:00:00   0.015       14\n",
              "720817  MAC000543      Std 2013-11-29 22:30:00   0.035       14\n",
              "720818  MAC000543      Std 2013-11-29 23:00:00   0.033       14\n",
              "720819  MAC000543      Std 2013-11-29 23:30:00   0.021       14\n",
              "720820  MAC000543      Std 2013-11-30 00:00:00   0.034       14\n",
              "\n",
              "[27878 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-140ee8eb-5aaa-4438-a4ec-325d887b1a16\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>LCLid</th>\n",
              "      <th>stdorToU</th>\n",
              "      <th>DateTime</th>\n",
              "      <th>KWH/hh</th>\n",
              "      <th>cluster</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>33347</th>\n",
              "      <td>MAC000025</td>\n",
              "      <td>Std</td>\n",
              "      <td>2013-11-01 00:00:00</td>\n",
              "      <td>0.021</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33348</th>\n",
              "      <td>MAC000025</td>\n",
              "      <td>Std</td>\n",
              "      <td>2013-11-01 00:30:00</td>\n",
              "      <td>0.005</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33349</th>\n",
              "      <td>MAC000025</td>\n",
              "      <td>Std</td>\n",
              "      <td>2013-11-01 01:00:00</td>\n",
              "      <td>0.025</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33350</th>\n",
              "      <td>MAC000025</td>\n",
              "      <td>Std</td>\n",
              "      <td>2013-11-01 01:30:00</td>\n",
              "      <td>0.013</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33351</th>\n",
              "      <td>MAC000025</td>\n",
              "      <td>Std</td>\n",
              "      <td>2013-11-01 02:00:00</td>\n",
              "      <td>0.005</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>720816</th>\n",
              "      <td>MAC000543</td>\n",
              "      <td>Std</td>\n",
              "      <td>2013-11-29 22:00:00</td>\n",
              "      <td>0.015</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>720817</th>\n",
              "      <td>MAC000543</td>\n",
              "      <td>Std</td>\n",
              "      <td>2013-11-29 22:30:00</td>\n",
              "      <td>0.035</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>720818</th>\n",
              "      <td>MAC000543</td>\n",
              "      <td>Std</td>\n",
              "      <td>2013-11-29 23:00:00</td>\n",
              "      <td>0.033</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>720819</th>\n",
              "      <td>MAC000543</td>\n",
              "      <td>Std</td>\n",
              "      <td>2013-11-29 23:30:00</td>\n",
              "      <td>0.021</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>720820</th>\n",
              "      <td>MAC000543</td>\n",
              "      <td>Std</td>\n",
              "      <td>2013-11-30 00:00:00</td>\n",
              "      <td>0.034</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>27878 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-140ee8eb-5aaa-4438-a4ec-325d887b1a16')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-140ee8eb-5aaa-4438-a4ec-325d887b1a16 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-140ee8eb-5aaa-4438-a4ec-325d887b1a16');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "37qDCzGKBuG-"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datan_2012 = []\n",
        "datan_2013 = []\n",
        "\n",
        "for i in range(tmfrme):\n",
        "    datan_2012.append(f_data_2012[i].copy())\n",
        "    datan_2013.append(f_data_2013[i].copy())\n",
        "\n",
        "datan_2013[8]"
      ],
      "metadata": {
        "id": "XXGohhJyBuD3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "9591f8c7-937f-45d2-d83c-054b341c0b7c"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            LCLid stdorToU            DateTime  KWH/hh  cluster\n",
              "30418   MAC000025      Std 2013-09-01 00:00:00   0.028       14\n",
              "30419   MAC000025      Std 2013-09-01 00:30:00   0.003       14\n",
              "30420   MAC000025      Std 2013-09-01 01:00:00   0.011       14\n",
              "30421   MAC000025      Std 2013-09-01 01:30:00   0.029       14\n",
              "30422   MAC000025      Std 2013-09-01 02:00:00   0.005       14\n",
              "...           ...      ...                 ...     ...      ...\n",
              "717887  MAC000543      Std 2013-09-29 22:00:00   0.031       14\n",
              "717888  MAC000543      Std 2013-09-29 22:30:00   0.035       14\n",
              "717889  MAC000543      Std 2013-09-29 23:00:00   0.015       14\n",
              "717890  MAC000543      Std 2013-09-29 23:30:00   0.035       14\n",
              "717891  MAC000543      Std 2013-09-30 00:00:00   0.034       14\n",
              "\n",
              "[27636 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e8c51499-e10d-4274-acb9-c1338d2321b4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>LCLid</th>\n",
              "      <th>stdorToU</th>\n",
              "      <th>DateTime</th>\n",
              "      <th>KWH/hh</th>\n",
              "      <th>cluster</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>30418</th>\n",
              "      <td>MAC000025</td>\n",
              "      <td>Std</td>\n",
              "      <td>2013-09-01 00:00:00</td>\n",
              "      <td>0.028</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30419</th>\n",
              "      <td>MAC000025</td>\n",
              "      <td>Std</td>\n",
              "      <td>2013-09-01 00:30:00</td>\n",
              "      <td>0.003</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30420</th>\n",
              "      <td>MAC000025</td>\n",
              "      <td>Std</td>\n",
              "      <td>2013-09-01 01:00:00</td>\n",
              "      <td>0.011</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30421</th>\n",
              "      <td>MAC000025</td>\n",
              "      <td>Std</td>\n",
              "      <td>2013-09-01 01:30:00</td>\n",
              "      <td>0.029</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30422</th>\n",
              "      <td>MAC000025</td>\n",
              "      <td>Std</td>\n",
              "      <td>2013-09-01 02:00:00</td>\n",
              "      <td>0.005</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>717887</th>\n",
              "      <td>MAC000543</td>\n",
              "      <td>Std</td>\n",
              "      <td>2013-09-29 22:00:00</td>\n",
              "      <td>0.031</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>717888</th>\n",
              "      <td>MAC000543</td>\n",
              "      <td>Std</td>\n",
              "      <td>2013-09-29 22:30:00</td>\n",
              "      <td>0.035</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>717889</th>\n",
              "      <td>MAC000543</td>\n",
              "      <td>Std</td>\n",
              "      <td>2013-09-29 23:00:00</td>\n",
              "      <td>0.015</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>717890</th>\n",
              "      <td>MAC000543</td>\n",
              "      <td>Std</td>\n",
              "      <td>2013-09-29 23:30:00</td>\n",
              "      <td>0.035</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>717891</th>\n",
              "      <td>MAC000543</td>\n",
              "      <td>Std</td>\n",
              "      <td>2013-09-30 00:00:00</td>\n",
              "      <td>0.034</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>27636 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e8c51499-e10d-4274-acb9-c1338d2321b4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e8c51499-e10d-4274-acb9-c1338d2321b4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e8c51499-e10d-4274-acb9-c1338d2321b4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(tmfrme):\n",
        "    datan_2012[i]['KWH/hh'] = datan_2012[i]['KWH/hh'].astype(np.float32)\n",
        "    datan_2013[i]['KWH/hh'] = datan_2013[i]['KWH/hh'].astype(np.float32)\n",
        "    datan_2012[i] = datan_2012[i].drop('cluster', axis=1)\n",
        "    datan_2012[i] = datan_2012[i].drop('stdorToU', axis=1)\n",
        "    datan_2013[i] = datan_2013[i].drop('cluster', axis=1)\n",
        "    datan_2013[i] = datan_2013[i].drop('stdorToU', axis=1)\n",
        "    datan_2012[i].reset_index(drop=True, inplace=True)\n",
        "    datan_2013[i].reset_index(drop=True, inplace=True)"
      ],
      "metadata": {
        "id": "k2J1s-NxIUsA"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(tmfrme):\n",
        "  datan_2012[i]['DateTime'] = pd.to_datetime(datan_2012[i].DateTime).dt.tz_localize(None)\n",
        "  datan_2013[i]['DateTime'] = pd.to_datetime(datan_2013[i].DateTime).dt.tz_localize(None)\n",
        "  for j in range(len(datan_2012[i])):\n",
        "    datan_2012[i]['DateTime'][j]=datan_2012[i]['DateTime'][j].timestamp()\n",
        "  for k in range(len(datan_2013[i])):\n",
        "    datan_2013[i]['DateTime'][k]=datan_2013[i]['DateTime'][k].timestamp()\n"
      ],
      "metadata": {
        "id": "mRCtomDjBt6z",
        "outputId": "27a49fa8-e88c-4c54-b82c-49ed8fdacaf1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-33-052dc1f6eda1>:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  datan_2012[i]['DateTime'][j]=datan_2012[i]['DateTime'][j].timestamp()\n",
            "<ipython-input-33-052dc1f6eda1>:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  datan_2013[i]['DateTime'][k]=datan_2013[i]['DateTime'][k].timestamp()\n",
            "<ipython-input-33-052dc1f6eda1>:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  datan_2012[i]['DateTime'][j]=datan_2012[i]['DateTime'][j].timestamp()\n",
            "<ipython-input-33-052dc1f6eda1>:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  datan_2013[i]['DateTime'][k]=datan_2013[i]['DateTime'][k].timestamp()\n",
            "<ipython-input-33-052dc1f6eda1>:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  datan_2012[i]['DateTime'][j]=datan_2012[i]['DateTime'][j].timestamp()\n",
            "<ipython-input-33-052dc1f6eda1>:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  datan_2013[i]['DateTime'][k]=datan_2013[i]['DateTime'][k].timestamp()\n",
            "<ipython-input-33-052dc1f6eda1>:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  datan_2012[i]['DateTime'][j]=datan_2012[i]['DateTime'][j].timestamp()\n",
            "<ipython-input-33-052dc1f6eda1>:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  datan_2013[i]['DateTime'][k]=datan_2013[i]['DateTime'][k].timestamp()\n",
            "<ipython-input-33-052dc1f6eda1>:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  datan_2012[i]['DateTime'][j]=datan_2012[i]['DateTime'][j].timestamp()\n",
            "<ipython-input-33-052dc1f6eda1>:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  datan_2013[i]['DateTime'][k]=datan_2013[i]['DateTime'][k].timestamp()\n",
            "<ipython-input-33-052dc1f6eda1>:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  datan_2012[i]['DateTime'][j]=datan_2012[i]['DateTime'][j].timestamp()\n",
            "<ipython-input-33-052dc1f6eda1>:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  datan_2013[i]['DateTime'][k]=datan_2013[i]['DateTime'][k].timestamp()\n",
            "<ipython-input-33-052dc1f6eda1>:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  datan_2012[i]['DateTime'][j]=datan_2012[i]['DateTime'][j].timestamp()\n",
            "<ipython-input-33-052dc1f6eda1>:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  datan_2013[i]['DateTime'][k]=datan_2013[i]['DateTime'][k].timestamp()\n",
            "<ipython-input-33-052dc1f6eda1>:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  datan_2012[i]['DateTime'][j]=datan_2012[i]['DateTime'][j].timestamp()\n",
            "<ipython-input-33-052dc1f6eda1>:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  datan_2013[i]['DateTime'][k]=datan_2013[i]['DateTime'][k].timestamp()\n",
            "<ipython-input-33-052dc1f6eda1>:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  datan_2012[i]['DateTime'][j]=datan_2012[i]['DateTime'][j].timestamp()\n",
            "<ipython-input-33-052dc1f6eda1>:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  datan_2013[i]['DateTime'][k]=datan_2013[i]['DateTime'][k].timestamp()\n",
            "<ipython-input-33-052dc1f6eda1>:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  datan_2012[i]['DateTime'][j]=datan_2012[i]['DateTime'][j].timestamp()\n",
            "<ipython-input-33-052dc1f6eda1>:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  datan_2013[i]['DateTime'][k]=datan_2013[i]['DateTime'][k].timestamp()\n",
            "<ipython-input-33-052dc1f6eda1>:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  datan_2012[i]['DateTime'][j]=datan_2012[i]['DateTime'][j].timestamp()\n",
            "<ipython-input-33-052dc1f6eda1>:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  datan_2013[i]['DateTime'][k]=datan_2013[i]['DateTime'][k].timestamp()\n",
            "<ipython-input-33-052dc1f6eda1>:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  datan_2012[i]['DateTime'][j]=datan_2012[i]['DateTime'][j].timestamp()\n",
            "<ipython-input-33-052dc1f6eda1>:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  datan_2013[i]['DateTime'][k]=datan_2013[i]['DateTime'][k].timestamp()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(tmfrme):\n",
        "  datan_2012[i]['DateTime'] = datan_2012[i]['DateTime'].astype(np.float32)\n",
        "  datan_2013[i]['DateTime'] = datan_2013[i]['DateTime'].astype(np.float32)\n",
        "  datan_2012[i].sort_values(['LCLid', 'DateTime'], inplace=True)\n",
        "  datan_2013[i].sort_values(['LCLid', 'DateTime'], inplace=True)\n"
      ],
      "metadata": {
        "id": "vbd9p8uYBt3Y"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the client window dataset function for a specific LCLid\n",
        "def create_client_dataset_for_LCLid(client_data, window_size, step_size):\n",
        "    client_windows = []\n",
        "    client_targets = []\n",
        "    num_readings = len(client_data)\n",
        "    \n",
        "    # Iterate over the readings using the sliding window\n",
        "    for i in range(0, num_readings - window_size, step_size):\n",
        "        window_start = i \n",
        "        window_end = i + window_size - 1\n",
        "        prediction_index = window_end + step_size\n",
        "        \n",
        "        # Extract the window and the prediction target\n",
        "        window = client_data.iloc[window_start:window_end + 1]['KWH/hh'].values\n",
        "        target = client_data.iloc[prediction_index]['KWH/hh']\n",
        "        \n",
        "        client_windows.append(window)\n",
        "        client_targets.append(target)\n",
        "    \n",
        "    # Create an ordered dictionary with 'x' and 'y' keys\n",
        "    ordered_dict = collections.OrderedDict()\n",
        "    ordered_dict['x'] = tf.stack(client_windows)\n",
        "    ordered_dict['y'] = tf.expand_dims(client_targets, axis=-1)\n",
        "    \n",
        "    \n",
        "    return ordered_dict"
      ],
      "metadata": {
        "id": "67FWJaipBtxd"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "window_size = 336\n",
        "step_size = 1\n",
        "\n",
        "# Filter the dataframe for the specific LCLid\n",
        "example_LCLid = datan_2012[0]['LCLid'].unique()[3]\n",
        "clientyy_data = datan_2012[0][datan_2012[0]['LCLid'] == example_LCLid]\n",
        "\n",
        "# Create the client dataset for the specific LCLid\n",
        "example_client_dataset = create_client_dataset_for_LCLid(clientyy_data, window_size, step_size)\n",
        "\n",
        "print(\"Client dataset for LCLid\", example_LCLid)\n",
        "print(example_client_dataset)"
      ],
      "metadata": {
        "id": "QmLKMsOQCOuA",
        "outputId": "5bc69467-b022-49c6-9960-e95e30cee540",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Client dataset for LCLid MAC000075\n",
            "OrderedDict([('x', <tf.Tensor: shape=(1106, 336), dtype=float32, numpy=\n",
            "array([[0.057, 0.032, 0.045, ..., 0.085, 0.064, 0.069],\n",
            "       [0.032, 0.045, 0.066, ..., 0.064, 0.069, 0.047],\n",
            "       [0.045, 0.066, 0.047, ..., 0.069, 0.047, 0.1  ],\n",
            "       ...,\n",
            "       [0.079, 0.088, 0.076, ..., 0.055, 0.086, 0.193],\n",
            "       [0.088, 0.076, 0.045, ..., 0.086, 0.193, 0.247],\n",
            "       [0.076, 0.045, 0.074, ..., 0.193, 0.247, 0.195]], dtype=float32)>), ('y', <tf.Tensor: shape=(1106, 1), dtype=float32, numpy=\n",
            "array([[0.047],\n",
            "       [0.1  ],\n",
            "       [0.066],\n",
            "       ...,\n",
            "       [0.247],\n",
            "       [0.195],\n",
            "       [0.052]], dtype=float32)>)])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_EPOCHS = 5\n",
        "BATCH_SIZE = 20\n",
        "SHUFFLE_BUFFER = 100\n",
        "PREFETCH_BUFFER = 10\n",
        "\n",
        "def preprocess_client_dataset(dataset):\n",
        "    def batch_format_fn(element):\n",
        "        return collections.OrderedDict(\n",
        "            x=tf.reshape(element['x'], [-1, 336]),\n",
        "            y=tf.reshape(element['y'], [-1, 1]))\n",
        "    return dataset.repeat(NUM_EPOCHS).shuffle(SHUFFLE_BUFFER).batch(\n",
        "        BATCH_SIZE).map(batch_format_fn).prefetch(PREFETCH_BUFFER)\n",
        " \n",
        "\n",
        "preprocessed_example_client_dataset = preprocess_client_dataset(tf.data.Dataset.from_tensor_slices(example_client_dataset))\n",
        "\n",
        "\n",
        "sample_batch = tf.nest.map_structure(lambda x: x.numpy(),\n",
        "                                     next(iter(preprocessed_example_client_dataset)))\n",
        "\n",
        "sample_batch"
      ],
      "metadata": {
        "id": "fMfxWbY5CR9m",
        "outputId": "18834418-f724-4215-a355-b681cb6c6196",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('x',\n",
              "              array([[0.086, 0.029, 0.061, ..., 0.04 , 0.071, 0.069],\n",
              "                     [0.051, 0.097, 0.035, ..., 0.085, 0.088, 0.089],\n",
              "                     [0.059, 0.029, 0.059, ..., 0.285, 0.119, 0.115],\n",
              "                     ...,\n",
              "                     [0.046, 0.03 , 0.109, ..., 0.074, 0.046, 0.112],\n",
              "                     [0.061, 0.028, 0.062, ..., 0.053, 0.078, 0.054],\n",
              "                     [0.078, 0.053, 0.043, ..., 0.271, 0.087, 0.1  ]], dtype=float32)),\n",
              "             ('y',\n",
              "              array([[0.22 ],\n",
              "                     [0.08 ],\n",
              "                     [0.111],\n",
              "                     [0.05 ],\n",
              "                     [0.062],\n",
              "                     [0.061],\n",
              "                     [0.044],\n",
              "                     [0.285],\n",
              "                     [0.04 ],\n",
              "                     [0.04 ],\n",
              "                     [0.05 ],\n",
              "                     [0.08 ],\n",
              "                     [0.062],\n",
              "                     [0.049],\n",
              "                     [0.078],\n",
              "                     [0.414],\n",
              "                     [0.071],\n",
              "                     [0.043],\n",
              "                     [0.085],\n",
              "                     [0.049]], dtype=float32))])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_CLIENTS = 10 # Replace with desired number of clients\n",
        "sample_clients_2012 = [] \n",
        "sample_clients_2013 = [] \n",
        "sample_clients_list_2012 = [] \n",
        "sample_clients_list_2013 = [] \n",
        "\n",
        "for i in range(tmfrme):\n",
        "  sample_clients_2012.append(datan_2012[i]['LCLid'].unique()[0:NUM_CLIENTS])\n",
        "  sample_clients_2013.append(datan_2013[i]['LCLid'].unique()[0:NUM_CLIENTS])\n",
        "  sample_clients_list_2012.append(sample_clients_2012[i].tolist())\n",
        "  sample_clients_list_2013.append(sample_clients_2013[i].tolist())\n",
        "\n",
        "sample_clients_list_2012[7]"
      ],
      "metadata": {
        "id": "pbyIUhc2CVY5",
        "outputId": "753140ee-df96-4af4-80fe-8396957cfa67",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['MAC000025',\n",
              " 'MAC000104',\n",
              " 'MAC000160',\n",
              " 'MAC000200',\n",
              " 'MAC000229',\n",
              " 'MAC000283',\n",
              " 'MAC000297',\n",
              " 'MAC000318',\n",
              " 'MAC000319',\n",
              " 'MAC000391']"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterate over unique LCLids in the dataframe\n",
        "client_datasets_2012_1 = {}\n",
        "for LCLid in sample_clients_list_2012[0]:\n",
        "    # Filter the dataframe for the current LCLid\n",
        "    client_data = datan_2012[0][datan_2012[0]['LCLid'] == LCLid]\n",
        "\n",
        "    clientxx_dataset = create_client_dataset_for_LCLid(client_data, window_size, step_size)\n",
        "    \n",
        "    # Create the client dataset for the current LCLid\n",
        "    preprocessed_client_dataset = preprocess_client_dataset(tf.data.Dataset.from_tensor_slices(clientxx_dataset))\n",
        "    \n",
        "    # Extract a sample batch from the preprocessed dataset\n",
        "    sam_batch = tf.nest.map_structure(lambda x: x.numpy(), next(iter(preprocessed_client_dataset)))\n",
        "    \n",
        "    # Store the preprocessed dataset in the dictionary with LCLid as the key\n",
        "    client_datasets_2012_1[LCLid] = preprocessed_client_dataset\n",
        "\n",
        "    print(\"Client dataset for LCLid\", LCLid)\n",
        "    print(sam_batch)"
      ],
      "metadata": {
        "id": "4mubGwDLCZJA",
        "outputId": "2f28c150-b619-449c-90a5-18c0eb381dea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Client dataset for LCLid MAC000025\n",
            "OrderedDict([('x', array([[0.042, 1.499, 0.56 , ..., 0.037, 0.014, 0.04 ],\n",
            "       [0.024, 0.   , 0.01 , ..., 0.   , 0.023, 0.002],\n",
            "       [0.016, 0.   , 0.459, ..., 0.   , 0.153, 0.057],\n",
            "       ...,\n",
            "       [0.   , 0.459, 0.227, ..., 0.153, 0.057, 0.598],\n",
            "       [0.011, 0.   , 0.02 , ..., 0.022, 0.   , 0.023],\n",
            "       [0.172, 0.068, 0.017, ..., 0.024, 0.   , 0.022]], dtype=float32)), ('y', array([[2.730e-01],\n",
            "       [1.600e-02],\n",
            "       [5.980e-01],\n",
            "       [7.500e-02],\n",
            "       [2.300e-02],\n",
            "       [5.400e-02],\n",
            "       [7.200e-02],\n",
            "       [6.900e-02],\n",
            "       [2.100e-02],\n",
            "       [0.000e+00],\n",
            "       [1.917e+00],\n",
            "       [2.300e-02],\n",
            "       [1.600e-02],\n",
            "       [7.300e-02],\n",
            "       [5.800e-02],\n",
            "       [7.700e-02],\n",
            "       [3.000e-03],\n",
            "       [7.140e-01],\n",
            "       [1.000e-03],\n",
            "       [3.700e-02]], dtype=float32))])\n",
            "Client dataset for LCLid MAC000048\n",
            "OrderedDict([('x', array([[0.111, 0.11 , 0.127, ..., 0.055, 0.054, 0.055],\n",
            "       [0.111, 0.113, 0.11 , ..., 0.055, 0.054, 0.072],\n",
            "       [0.131, 0.141, 0.128, ..., 0.055, 0.056, 0.059],\n",
            "       ...,\n",
            "       [0.056, 0.055, 0.055, ..., 0.056, 0.083, 0.082],\n",
            "       [2.026, 0.681, 0.63 , ..., 0.228, 0.202, 0.195],\n",
            "       [0.11 , 0.111, 0.133, ..., 0.464, 0.475, 0.462]], dtype=float32)), ('y', array([[0.055],\n",
            "       [0.081],\n",
            "       [0.082],\n",
            "       [0.059],\n",
            "       [0.147],\n",
            "       [0.256],\n",
            "       [0.057],\n",
            "       [0.756],\n",
            "       [0.218],\n",
            "       [0.056],\n",
            "       [0.159],\n",
            "       [0.057],\n",
            "       [0.192],\n",
            "       [0.072],\n",
            "       [0.056],\n",
            "       [0.475],\n",
            "       [0.091],\n",
            "       [0.065],\n",
            "       [0.369],\n",
            "       [0.443]], dtype=float32))])\n",
            "Client dataset for LCLid MAC000065\n",
            "OrderedDict([('x', array([[0.265, 0.297, 0.057, ..., 0.032, 0.193, 0.048],\n",
            "       [0.058, 0.439, 0.101, ..., 0.527, 0.105, 0.039],\n",
            "       [0.029, 0.03 , 0.032, ..., 0.016, 0.033, 0.014],\n",
            "       ...,\n",
            "       [0.307, 0.333, 0.348, ..., 0.121, 0.133, 0.355],\n",
            "       [0.122, 0.04 , 0.122, ..., 0.045, 0.027, 0.093],\n",
            "       [0.021, 0.031, 0.031, ..., 0.029, 0.032, 0.023]], dtype=float32)), ('y', array([[0.061],\n",
            "       [0.048],\n",
            "       [0.034],\n",
            "       [0.142],\n",
            "       [0.038],\n",
            "       [0.133],\n",
            "       [0.021],\n",
            "       [0.102],\n",
            "       [0.028],\n",
            "       [0.088],\n",
            "       [0.029],\n",
            "       [0.229],\n",
            "       [0.121],\n",
            "       [0.032],\n",
            "       [0.031],\n",
            "       [0.021],\n",
            "       [0.245],\n",
            "       [0.281],\n",
            "       [0.527],\n",
            "       [0.023]], dtype=float32))])\n",
            "Client dataset for LCLid MAC000075\n",
            "OrderedDict([('x', array([[0.063, 0.031, 0.092, ..., 0.05 , 0.05 , 0.04 ],\n",
            "       [0.03 , 0.083, 0.049, ..., 0.22 , 0.097, 0.066],\n",
            "       [0.039, 0.063, 0.065, ..., 0.088, 0.044, 0.064],\n",
            "       ...,\n",
            "       [0.029, 0.059, 0.07 , ..., 0.119, 0.115, 0.111],\n",
            "       [0.07 , 0.043, 0.046, ..., 0.111, 0.043, 0.074],\n",
            "       [0.049, 0.038, 1.29 , ..., 0.049, 0.079, 0.06 ]], dtype=float32)), ('y', array([[0.088],\n",
            "       [0.072],\n",
            "       [0.034],\n",
            "       [0.085],\n",
            "       [0.12 ],\n",
            "       [0.056],\n",
            "       [0.045],\n",
            "       [0.063],\n",
            "       [0.089],\n",
            "       [0.116],\n",
            "       [0.329],\n",
            "       [0.111],\n",
            "       [0.084],\n",
            "       [0.053],\n",
            "       [0.066],\n",
            "       [0.082],\n",
            "       [0.285],\n",
            "       [0.043],\n",
            "       [0.046],\n",
            "       [0.036]], dtype=float32))])\n",
            "Client dataset for LCLid MAC000104\n",
            "OrderedDict([('x', array([[0.088, 0.101, 0.695, ..., 0.102, 0.096, 0.25 ],\n",
            "       [0.162, 0.179, 0.076, ..., 0.337, 0.281, 0.053],\n",
            "       [0.053, 0.103, 0.11 , ..., 0.096, 0.096, 0.095],\n",
            "       ...,\n",
            "       [0.347, 0.241, 0.256, ..., 0.468, 0.239, 0.728],\n",
            "       [0.042, 0.046, 0.063, ..., 0.033, 0.033, 0.066],\n",
            "       [0.241, 0.256, 0.162, ..., 0.239, 0.728, 0.337]], dtype=float32)), ('y', array([[0.212],\n",
            "       [0.068],\n",
            "       [0.095],\n",
            "       [0.175],\n",
            "       [0.233],\n",
            "       [0.468],\n",
            "       [0.096],\n",
            "       [0.123],\n",
            "       [0.053],\n",
            "       [0.371],\n",
            "       [0.285],\n",
            "       [0.084],\n",
            "       [0.166],\n",
            "       [0.033],\n",
            "       [0.327],\n",
            "       [0.43 ],\n",
            "       [0.239],\n",
            "       [0.337],\n",
            "       [0.102],\n",
            "       [0.281]], dtype=float32))])\n",
            "Client dataset for LCLid MAC000160\n",
            "OrderedDict([('x', array([[0.054, 0.04 , 0.041, ..., 0.039, 0.1  , 0.071],\n",
            "       [0.056, 0.034, 0.056, ..., 0.099, 0.07 , 0.141],\n",
            "       [0.136, 0.225, 0.434, ..., 0.046, 0.04 , 0.056],\n",
            "       ...,\n",
            "       [0.041, 0.056, 0.027, ..., 0.028, 0.055, 0.038],\n",
            "       [0.05 , 0.042, 0.037, ..., 0.055, 0.027, 0.055],\n",
            "       [0.41 , 0.256, 0.239, ..., 0.475, 0.247, 0.232]], dtype=float32)), ('y', array([[0.098],\n",
            "       [0.037],\n",
            "       [0.031],\n",
            "       [0.067],\n",
            "       [0.062],\n",
            "       [0.05 ],\n",
            "       [0.033],\n",
            "       [0.087],\n",
            "       [0.185],\n",
            "       [0.102],\n",
            "       [0.198],\n",
            "       [0.057],\n",
            "       [0.056],\n",
            "       [0.129],\n",
            "       [0.055],\n",
            "       [0.041],\n",
            "       [0.029],\n",
            "       [0.049],\n",
            "       [0.027],\n",
            "       [0.322]], dtype=float32))])\n",
            "Client dataset for LCLid MAC000200\n",
            "OrderedDict([('x', array([[0.013, 0.014, 0.063, ..., 0.014, 0.012, 0.013],\n",
            "       [0.078, 0.079, 0.025, ..., 0.025, 0.025, 0.036],\n",
            "       [0.013, 0.012, 0.021, ..., 0.107, 0.118, 0.079],\n",
            "       ...,\n",
            "       [0.044, 0.036, 0.012, ..., 0.073, 0.067, 0.092],\n",
            "       [0.024, 0.025, 0.063, ..., 0.15 , 1.233, 0.18 ],\n",
            "       [0.012, 0.111, 0.261, ..., 0.012, 0.051, 0.053]], dtype=float32)), ('y', array([[0.025],\n",
            "       [0.077],\n",
            "       [0.275],\n",
            "       [0.013],\n",
            "       [0.012],\n",
            "       [0.135],\n",
            "       [0.037],\n",
            "       [0.107],\n",
            "       [0.029],\n",
            "       [0.269],\n",
            "       [0.07 ],\n",
            "       [0.031],\n",
            "       [0.148],\n",
            "       [0.062],\n",
            "       [0.069],\n",
            "       [0.03 ],\n",
            "       [0.028],\n",
            "       [0.056],\n",
            "       [0.599],\n",
            "       [0.012]], dtype=float32))])\n",
            "Client dataset for LCLid MAC000229\n",
            "OrderedDict([('x', array([[0.177, 0.137, 0.111, ..., 0.087, 0.097, 0.071],\n",
            "       [0.243, 0.174, 0.196, ..., 0.103, 0.101, 0.103],\n",
            "       [0.291, 0.183, 0.182, ..., 0.192, 0.186, 0.291],\n",
            "       ...,\n",
            "       [0.252, 0.181, 0.338, ..., 0.268, 0.242, 0.391],\n",
            "       [0.774, 0.347, 0.139, ..., 0.257, 0.262, 0.327],\n",
            "       [0.313, 0.173, 0.161, ..., 0.248, 0.16 , 0.221]], dtype=float32)), ('y', array([[0.086],\n",
            "       [0.12 ],\n",
            "       [0.182],\n",
            "       [0.19 ],\n",
            "       [0.057],\n",
            "       [0.09 ],\n",
            "       [0.125],\n",
            "       [0.088],\n",
            "       [0.11 ],\n",
            "       [0.353],\n",
            "       [0.085],\n",
            "       [0.551],\n",
            "       [0.257],\n",
            "       [0.088],\n",
            "       [0.084],\n",
            "       [0.101],\n",
            "       [0.242],\n",
            "       [0.21 ],\n",
            "       [0.841],\n",
            "       [0.213]], dtype=float32))])\n",
            "Client dataset for LCLid MAC004461\n",
            "OrderedDict([('x', array([[0.17 , 0.084, 0.103, ..., 0.117, 0.055, 0.082],\n",
            "       [0.099, 0.066, 0.1  , ..., 0.162, 0.095, 0.077],\n",
            "       [0.1  , 0.027, 0.048, ..., 0.094, 0.057, 0.049],\n",
            "       ...,\n",
            "       [0.103, 0.092, 0.064, ..., 0.082, 0.268, 0.081],\n",
            "       [0.099, 0.139, 0.11 , ..., 0.08 , 0.076, 0.18 ],\n",
            "       [0.139, 0.11 , 0.099, ..., 0.076, 0.18 , 0.162]], dtype=float32)), ('y', array([[0.268],\n",
            "       [0.075],\n",
            "       [0.016],\n",
            "       [0.077],\n",
            "       [0.095],\n",
            "       [0.109],\n",
            "       [0.02 ],\n",
            "       [0.079],\n",
            "       [0.076],\n",
            "       [0.083],\n",
            "       [0.144],\n",
            "       [0.115],\n",
            "       [0.084],\n",
            "       [0.082],\n",
            "       [0.083],\n",
            "       [0.081],\n",
            "       [0.018],\n",
            "       [0.112],\n",
            "       [0.162],\n",
            "       [0.095]], dtype=float32))])\n",
            "Client dataset for LCLid MAC004481\n",
            "OrderedDict([('x', array([[0.061, 0.033, 0.033, ..., 0.028, 0.191, 0.252],\n",
            "       [0.045, 0.053, 0.078, ..., 0.102, 0.047, 0.127],\n",
            "       [0.047, 0.028, 0.   , ..., 0.057, 0.052, 0.047],\n",
            "       ...,\n",
            "       [0.074, 0.067, 0.026, ..., 0.03 , 0.042, 0.088],\n",
            "       [0.308, 0.106, 0.056, ..., 0.309, 0.065, 0.257],\n",
            "       [0.048, 0.086, 0.049, ..., 0.054, 0.04 , 0.031]], dtype=float32)), ('y', array([[0.091],\n",
            "       [0.046],\n",
            "       [0.082],\n",
            "       [0.03 ],\n",
            "       [0.085],\n",
            "       [0.092],\n",
            "       [0.057],\n",
            "       [0.071],\n",
            "       [0.028],\n",
            "       [0.083],\n",
            "       [0.096],\n",
            "       [0.123],\n",
            "       [0.054],\n",
            "       [0.128],\n",
            "       [0.049],\n",
            "       [0.059],\n",
            "       [0.065],\n",
            "       [0.077],\n",
            "       [0.068],\n",
            "       [0.058]], dtype=float32))])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterate over unique LCLids in the dataframe\n",
        "client_datasets_2012_2 = {}\n",
        "for LCLid in sample_clients_list_2012[1]:\n",
        "    # Filter the dataframe for the current LCLid\n",
        "    client_data = datan_2012[1][datan_2012[1]['LCLid'] == LCLid]\n",
        "\n",
        "    clientxx_dataset = create_client_dataset_for_LCLid(client_data, window_size, step_size)\n",
        "    \n",
        "    # Create the client dataset for the current LCLid\n",
        "    preprocessed_client_dataset = preprocess_client_dataset(tf.data.Dataset.from_tensor_slices(clientxx_dataset))\n",
        "    \n",
        "    # Extract a sample batch from the preprocessed dataset\n",
        "    sam_batch = tf.nest.map_structure(lambda x: x.numpy(), next(iter(preprocessed_client_dataset)))\n",
        "    \n",
        "    # Store the preprocessed dataset in the dictionary with LCLid as the key\n",
        "    client_datasets_2012_2[LCLid] = preprocessed_client_dataset\n"
      ],
      "metadata": {
        "id": "red6wddKREYj"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterate over unique LCLids in the dataframe\n",
        "client_datasets_2012_3 = {}\n",
        "for LCLid in sample_clients_list_2012[2]:\n",
        "    # Filter the dataframe for the current LCLid\n",
        "    client_data = datan_2012[2][datan_2012[2]['LCLid'] == LCLid]\n",
        "\n",
        "    clientxx_dataset = create_client_dataset_for_LCLid(client_data, window_size, step_size)\n",
        "    \n",
        "    # Create the client dataset for the current LCLid\n",
        "    preprocessed_client_dataset = preprocess_client_dataset(tf.data.Dataset.from_tensor_slices(clientxx_dataset))\n",
        "    \n",
        "    # Extract a sample batch from the preprocessed dataset\n",
        "    sam_batch = tf.nest.map_structure(lambda x: x.numpy(), next(iter(preprocessed_client_dataset)))\n",
        "    \n",
        "    # Store the preprocessed dataset in the dictionary with LCLid as the key\n",
        "    client_datasets_2012_3[LCLid] = preprocessed_client_dataset"
      ],
      "metadata": {
        "id": "CpV5aLuUREV5"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterate over unique LCLids in the dataframe\n",
        "client_datasets_2012_4 = {}\n",
        "for LCLid in sample_clients_list_2012[3]:\n",
        "    # Filter the dataframe for the current LCLid\n",
        "    client_data = datan_2012[3][datan_2012[3]['LCLid'] == LCLid]\n",
        "\n",
        "    clientxx_dataset = create_client_dataset_for_LCLid(client_data, window_size, step_size)\n",
        "    \n",
        "    # Create the client dataset for the current LCLid\n",
        "    preprocessed_client_dataset = preprocess_client_dataset(tf.data.Dataset.from_tensor_slices(clientxx_dataset))\n",
        "    \n",
        "    # Extract a sample batch from the preprocessed dataset\n",
        "    sam_batch = tf.nest.map_structure(lambda x: x.numpy(), next(iter(preprocessed_client_dataset)))\n",
        "    \n",
        "    # Store the preprocessed dataset in the dictionary with LCLid as the key\n",
        "    client_datasets_2012_4[LCLid] = preprocessed_client_dataset"
      ],
      "metadata": {
        "id": "RxliEnhLRESz"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterate over unique LCLids in the dataframe\n",
        "client_datasets_2012_5 = {}\n",
        "for LCLid in sample_clients_list_2012[4]:\n",
        "    # Filter the dataframe for the current LCLid\n",
        "    client_data = datan_2012[4][datan_2012[4]['LCLid'] == LCLid]\n",
        "\n",
        "    clientxx_dataset = create_client_dataset_for_LCLid(client_data, window_size, step_size)\n",
        "    \n",
        "    # Create the client dataset for the current LCLid\n",
        "    preprocessed_client_dataset = preprocess_client_dataset(tf.data.Dataset.from_tensor_slices(clientxx_dataset))\n",
        "    \n",
        "    # Extract a sample batch from the preprocessed dataset\n",
        "    sam_batch = tf.nest.map_structure(lambda x: x.numpy(), next(iter(preprocessed_client_dataset)))\n",
        "    \n",
        "    # Store the preprocessed dataset in the dictionary with LCLid as the key\n",
        "    client_datasets_2012_5[LCLid] = preprocessed_client_dataset"
      ],
      "metadata": {
        "id": "oru1ITcVREQb"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterate over unique LCLids in the dataframe\n",
        "client_datasets_2012_6 = {}\n",
        "for LCLid in sample_clients_list_2012[5]:\n",
        "    # Filter the dataframe for the current LCLid\n",
        "    client_data = datan_2012[5][datan_2012[5]['LCLid'] == LCLid]\n",
        "\n",
        "    clientxx_dataset = create_client_dataset_for_LCLid(client_data, window_size, step_size)\n",
        "    \n",
        "    # Create the client dataset for the current LCLid\n",
        "    preprocessed_client_dataset = preprocess_client_dataset(tf.data.Dataset.from_tensor_slices(clientxx_dataset))\n",
        "    \n",
        "    # Extract a sample batch from the preprocessed dataset\n",
        "    sam_batch = tf.nest.map_structure(lambda x: x.numpy(), next(iter(preprocessed_client_dataset)))\n",
        "    \n",
        "    # Store the preprocessed dataset in the dictionary with LCLid as the key\n",
        "    client_datasets_2012_6[LCLid] = preprocessed_client_dataset"
      ],
      "metadata": {
        "id": "pbvi3O9fRENi"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterate over unique LCLids in the dataframe\n",
        "client_datasets_2012_7 = {}\n",
        "for LCLid in sample_clients_list_2012[6]:\n",
        "    # Filter the dataframe for the current LCLid\n",
        "    client_data = datan_2012[6][datan_2012[6]['LCLid'] == LCLid]\n",
        "\n",
        "    clientxx_dataset = create_client_dataset_for_LCLid(client_data, window_size, step_size)\n",
        "    \n",
        "    # Create the client dataset for the current LCLid\n",
        "    preprocessed_client_dataset = preprocess_client_dataset(tf.data.Dataset.from_tensor_slices(clientxx_dataset))\n",
        "    \n",
        "    # Extract a sample batch from the preprocessed dataset\n",
        "    sam_batch = tf.nest.map_structure(lambda x: x.numpy(), next(iter(preprocessed_client_dataset)))\n",
        "    \n",
        "    # Store the preprocessed dataset in the dictionary with LCLid as the key\n",
        "    client_datasets_2012_7[LCLid] = preprocessed_client_dataset"
      ],
      "metadata": {
        "id": "V7tOPfBdREKd"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterate over unique LCLids in the dataframe\n",
        "client_datasets_2012_8 = {}\n",
        "for LCLid in sample_clients_list_2012[7]:\n",
        "    # Filter the dataframe for the current LCLid\n",
        "    client_data = datan_2012[7][datan_2012[7]['LCLid'] == LCLid]\n",
        "\n",
        "    clientxx_dataset = create_client_dataset_for_LCLid(client_data, window_size, step_size)\n",
        "    \n",
        "    # Create the client dataset for the current LCLid\n",
        "    preprocessed_client_dataset = preprocess_client_dataset(tf.data.Dataset.from_tensor_slices(clientxx_dataset))\n",
        "    \n",
        "    # Extract a sample batch from the preprocessed dataset\n",
        "    sam_batch = tf.nest.map_structure(lambda x: x.numpy(), next(iter(preprocessed_client_dataset)))\n",
        "    \n",
        "    # Store the preprocessed dataset in the dictionary with LCLid as the key\n",
        "    client_datasets_2012_8[LCLid] = preprocessed_client_dataset"
      ],
      "metadata": {
        "id": "NsNcXL6OREHd"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterate over unique LCLids in the dataframe\n",
        "client_datasets_2012_9 = {}\n",
        "for LCLid in sample_clients_list_2012[8]:\n",
        "    # Filter the dataframe for the current LCLid\n",
        "    client_data = datan_2012[8][datan_2012[8]['LCLid'] == LCLid]\n",
        "\n",
        "    clientxx_dataset = create_client_dataset_for_LCLid(client_data, window_size, step_size)\n",
        "    \n",
        "    # Create the client dataset for the current LCLid\n",
        "    preprocessed_client_dataset = preprocess_client_dataset(tf.data.Dataset.from_tensor_slices(clientxx_dataset))\n",
        "    \n",
        "    # Extract a sample batch from the preprocessed dataset\n",
        "    sam_batch = tf.nest.map_structure(lambda x: x.numpy(), next(iter(preprocessed_client_dataset)))\n",
        "    \n",
        "    # Store the preprocessed dataset in the dictionary with LCLid as the key\n",
        "    client_datasets_2012_9[LCLid] = preprocessed_client_dataset"
      ],
      "metadata": {
        "id": "ZF3LcV5vREEe"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterate over unique LCLids in the dataframe\n",
        "client_datasets_2012_10 = {}\n",
        "for LCLid in sample_clients_list_2012[9]:\n",
        "    # Filter the dataframe for the current LCLid\n",
        "    client_data = datan_2012[9][datan_2012[9]['LCLid'] == LCLid]\n",
        "\n",
        "    clientxx_dataset = create_client_dataset_for_LCLid(client_data, window_size, step_size)\n",
        "    \n",
        "    # Create the client dataset for the current LCLid\n",
        "    preprocessed_client_dataset = preprocess_client_dataset(tf.data.Dataset.from_tensor_slices(clientxx_dataset))\n",
        "    \n",
        "    # Extract a sample batch from the preprocessed dataset\n",
        "    sam_batch = tf.nest.map_structure(lambda x: x.numpy(), next(iter(preprocessed_client_dataset)))\n",
        "    \n",
        "    # Store the preprocessed dataset in the dictionary with LCLid as the key\n",
        "    client_datasets_2012_10[LCLid] = preprocessed_client_dataset"
      ],
      "metadata": {
        "id": "SwN3mI7_REBp"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterate over unique LCLids in the dataframe\n",
        "client_datasets_2012_11 = {}\n",
        "for LCLid in sample_clients_list_2012[10]:\n",
        "    # Filter the dataframe for the current LCLid\n",
        "    client_data = datan_2012[11][datan_2012[11]['LCLid'] == LCLid]\n",
        "\n",
        "    clientxx_dataset = create_client_dataset_for_LCLid(client_data, window_size, step_size)\n",
        "    \n",
        "    # Create the client dataset for the current LCLid\n",
        "    preprocessed_client_dataset = preprocess_client_dataset(tf.data.Dataset.from_tensor_slices(clientxx_dataset))\n",
        "    \n",
        "    # Extract a sample batch from the preprocessed dataset\n",
        "    sam_batch = tf.nest.map_structure(lambda x: x.numpy(), next(iter(preprocessed_client_dataset)))\n",
        "    \n",
        "    # Store the preprocessed dataset in the dictionary with LCLid as the key\n",
        "    client_datasets_2012_11[LCLid] = preprocessed_client_dataset"
      ],
      "metadata": {
        "id": "oR2LKYggRD-k"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterate over unique LCLids in the dataframe\n",
        "client_datasets_2012_12 = {}\n",
        "for LCLid in sample_clients_list_2012[11]:\n",
        "    # Filter the dataframe for the current LCLid\n",
        "    client_data = datan_2012[11][datan_2012[11]['LCLid'] == LCLid]\n",
        "\n",
        "    clientxx_dataset = create_client_dataset_for_LCLid(client_data, window_size, step_size)\n",
        "    \n",
        "    # Create the client dataset for the current LCLid\n",
        "    preprocessed_client_dataset = preprocess_client_dataset(tf.data.Dataset.from_tensor_slices(clientxx_dataset))\n",
        "    \n",
        "    # Extract a sample batch from the preprocessed dataset\n",
        "    sam_batch = tf.nest.map_structure(lambda x: x.numpy(), next(iter(preprocessed_client_dataset)))\n",
        "    \n",
        "    # Store the preprocessed dataset in the dictionary with LCLid as the key\n",
        "    client_datasets_2012_12[LCLid] = preprocessed_client_dataset"
      ],
      "metadata": {
        "id": "Wd9zngAURD7m"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterate over unique LCLids in the dataframe\n",
        "client_datasets_2013_1 = {}\n",
        "for LCLid in sample_clients_list_2013[0]:\n",
        "    # Filter the dataframe for the current LCLid\n",
        "    client_data = datan_2013[0][datan_2013[0]['LCLid'] == LCLid]\n",
        "\n",
        "    clientxx_dataset = create_client_dataset_for_LCLid(client_data, window_size, step_size)\n",
        "    \n",
        "    # Create the client dataset for the current LCLid\n",
        "    preprocessed_client_dataset = preprocess_client_dataset(tf.data.Dataset.from_tensor_slices(clientxx_dataset))\n",
        "    \n",
        "    # Extract a sample batch from the preprocessed dataset\n",
        "    sam_batch = tf.nest.map_structure(lambda x: x.numpy(), next(iter(preprocessed_client_dataset)))\n",
        "    \n",
        "    # Store the preprocessed dataset in the dictionary with LCLid as the key\n",
        "    client_datasets_2013_1[LCLid] = preprocessed_client_dataset"
      ],
      "metadata": {
        "id": "LIeGS_A7RD4g"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterate over unique LCLids in the dataframe\n",
        "client_datasets_2013_2 = {}\n",
        "for LCLid in sample_clients_list_2013[1]:\n",
        "    # Filter the dataframe for the current LCLid\n",
        "    client_data = datan_2013[1][datan_2013[1]['LCLid'] == LCLid]\n",
        "\n",
        "    clientxx_dataset = create_client_dataset_for_LCLid(client_data, window_size, step_size)\n",
        "    \n",
        "    # Create the client dataset for the current LCLid\n",
        "    preprocessed_client_dataset = preprocess_client_dataset(tf.data.Dataset.from_tensor_slices(clientxx_dataset))\n",
        "    \n",
        "    # Extract a sample batch from the preprocessed dataset\n",
        "    sam_batch = tf.nest.map_structure(lambda x: x.numpy(), next(iter(preprocessed_client_dataset)))\n",
        "    \n",
        "    # Store the preprocessed dataset in the dictionary with LCLid as the key\n",
        "    client_datasets_2013_2[LCLid] = preprocessed_client_dataset"
      ],
      "metadata": {
        "id": "ciAe20PSRD09"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterate over unique LCLids in the dataframe\n",
        "client_datasets_2013_3 = {}\n",
        "for LCLid in sample_clients_list_2013[2]:\n",
        "    # Filter the dataframe for the current LCLid\n",
        "    client_data = datan_2013[2][datan_2013[2]['LCLid'] == LCLid]\n",
        "\n",
        "    clientxx_dataset = create_client_dataset_for_LCLid(client_data, window_size, step_size)\n",
        "    \n",
        "    # Create the client dataset for the current LCLid\n",
        "    preprocessed_client_dataset = preprocess_client_dataset(tf.data.Dataset.from_tensor_slices(clientxx_dataset))\n",
        "    \n",
        "    # Extract a sample batch from the preprocessed dataset\n",
        "    sam_batch = tf.nest.map_structure(lambda x: x.numpy(), next(iter(preprocessed_client_dataset)))\n",
        "    \n",
        "    # Store the preprocessed dataset in the dictionary with LCLid as the key\n",
        "    client_datasets_2013_3[LCLid] = preprocessed_client_dataset"
      ],
      "metadata": {
        "id": "IRRtP_wwRDxt"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterate over unique LCLids in the dataframe\n",
        "client_datasets_2013_4 = {}\n",
        "for LCLid in sample_clients_list_2013[3]:\n",
        "    # Filter the dataframe for the current LCLid\n",
        "    client_data = datan_2013[3][datan_2013[3]['LCLid'] == LCLid]\n",
        "\n",
        "    clientxx_dataset = create_client_dataset_for_LCLid(client_data, window_size, step_size)\n",
        "    \n",
        "    # Create the client dataset for the current LCLid\n",
        "    preprocessed_client_dataset = preprocess_client_dataset(tf.data.Dataset.from_tensor_slices(clientxx_dataset))\n",
        "    \n",
        "    # Extract a sample batch from the preprocessed dataset\n",
        "    sam_batch = tf.nest.map_structure(lambda x: x.numpy(), next(iter(preprocessed_client_dataset)))\n",
        "    \n",
        "    # Store the preprocessed dataset in the dictionary with LCLid as the key\n",
        "    client_datasets_2013_4[LCLid] = preprocessed_client_dataset"
      ],
      "metadata": {
        "id": "YlAsCgPeTRMU"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterate over unique LCLids in the dataframe\n",
        "client_datasets_2013_5 = {}\n",
        "for LCLid in sample_clients_list_2013[4]:\n",
        "    # Filter the dataframe for the current LCLid\n",
        "    client_data = datan_2013[4][datan_2013[4]['LCLid'] == LCLid]\n",
        "\n",
        "    clientxx_dataset = create_client_dataset_for_LCLid(client_data, window_size, step_size)\n",
        "    \n",
        "    # Create the client dataset for the current LCLid\n",
        "    preprocessed_client_dataset = preprocess_client_dataset(tf.data.Dataset.from_tensor_slices(clientxx_dataset))\n",
        "    \n",
        "    # Extract a sample batch from the preprocessed dataset\n",
        "    sam_batch = tf.nest.map_structure(lambda x: x.numpy(), next(iter(preprocessed_client_dataset)))\n",
        "    \n",
        "    # Store the preprocessed dataset in the dictionary with LCLid as the key\n",
        "    client_datasets_2013_5[LCLid] = preprocessed_client_dataset"
      ],
      "metadata": {
        "id": "Js2OqQz5TRE-"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterate over unique LCLids in the dataframe\n",
        "client_datasets_2013_6 = {}\n",
        "for LCLid in sample_clients_list_2013[5]:\n",
        "    # Filter the dataframe for the current LCLid\n",
        "    client_data = datan_2013[5][datan_2013[5]['LCLid'] == LCLid]\n",
        "\n",
        "    clientxx_dataset = create_client_dataset_for_LCLid(client_data, window_size, step_size)\n",
        "    \n",
        "    # Create the client dataset for the current LCLid\n",
        "    preprocessed_client_dataset = preprocess_client_dataset(tf.data.Dataset.from_tensor_slices(clientxx_dataset))\n",
        "    \n",
        "    # Extract a sample batch from the preprocessed dataset\n",
        "    sam_batch = tf.nest.map_structure(lambda x: x.numpy(), next(iter(preprocessed_client_dataset)))\n",
        "    \n",
        "    # Store the preprocessed dataset in the dictionary with LCLid as the key\n",
        "    client_datasets_2013_6[LCLid] = preprocessed_client_dataset"
      ],
      "metadata": {
        "id": "PmK8x32rTQwU"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterate over unique LCLids in the dataframe\n",
        "client_datasets_2013_7 = {}\n",
        "for LCLid in sample_clients_list_2013[6]:\n",
        "    # Filter the dataframe for the current LCLid\n",
        "    client_data = datan_2013[6][datan_2013[6]['LCLid'] == LCLid]\n",
        "\n",
        "    clientxx_dataset = create_client_dataset_for_LCLid(client_data, window_size, step_size)\n",
        "    \n",
        "    # Create the client dataset for the current LCLid\n",
        "    preprocessed_client_dataset = preprocess_client_dataset(tf.data.Dataset.from_tensor_slices(clientxx_dataset))\n",
        "    \n",
        "    # Extract a sample batch from the preprocessed dataset\n",
        "    sam_batch = tf.nest.map_structure(lambda x: x.numpy(), next(iter(preprocessed_client_dataset)))\n",
        "    \n",
        "    # Store the preprocessed dataset in the dictionary with LCLid as the key\n",
        "    client_datasets_2013_7[LCLid] = preprocessed_client_dataset"
      ],
      "metadata": {
        "id": "42eBapf9TQnz"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterate over unique LCLids in the dataframe\n",
        "client_datasets_2013_8 = {}\n",
        "for LCLid in sample_clients_list_2013[7]:\n",
        "    # Filter the dataframe for the current LCLid\n",
        "    client_data = datan_2013[7][datan_2013[7]['LCLid'] == LCLid]\n",
        "\n",
        "    clientxx_dataset = create_client_dataset_for_LCLid(client_data, window_size, step_size)\n",
        "    \n",
        "    # Create the client dataset for the current LCLid\n",
        "    preprocessed_client_dataset = preprocess_client_dataset(tf.data.Dataset.from_tensor_slices(clientxx_dataset))\n",
        "    \n",
        "    # Extract a sample batch from the preprocessed dataset\n",
        "    sam_batch = tf.nest.map_structure(lambda x: x.numpy(), next(iter(preprocessed_client_dataset)))\n",
        "    \n",
        "    # Store the preprocessed dataset in the dictionary with LCLid as the key\n",
        "    client_datasets_2013_8[LCLid] = preprocessed_client_dataset"
      ],
      "metadata": {
        "id": "bnkMqituTQgE"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterate over unique LCLids in the dataframe\n",
        "client_datasets_2013_9 = {}\n",
        "for LCLid in sample_clients_list_2013[8]:\n",
        "    # Filter the dataframe for the current LCLid\n",
        "    client_data = datan_2013[8][datan_2013[8]['LCLid'] == LCLid]\n",
        "\n",
        "    clientxx_dataset = create_client_dataset_for_LCLid(client_data, window_size, step_size)\n",
        "    \n",
        "    # Create the client dataset for the current LCLid\n",
        "    preprocessed_client_dataset = preprocess_client_dataset(tf.data.Dataset.from_tensor_slices(clientxx_dataset))\n",
        "    \n",
        "    # Extract a sample batch from the preprocessed dataset\n",
        "    sam_batch = tf.nest.map_structure(lambda x: x.numpy(), next(iter(preprocessed_client_dataset)))\n",
        "    \n",
        "    # Store the preprocessed dataset in the dictionary with LCLid as the key\n",
        "    client_datasets_2013_9[LCLid] = preprocessed_client_dataset"
      ],
      "metadata": {
        "id": "4OhvN9K-TQYF"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterate over unique LCLids in the dataframe\n",
        "client_datasets_2013_10 = {}\n",
        "for LCLid in sample_clients_list_2013[9]:\n",
        "    # Filter the dataframe for the current LCLid\n",
        "    client_data = datan_2013[9][datan_2013[9]['LCLid'] == LCLid]\n",
        "\n",
        "    clientxx_dataset = create_client_dataset_for_LCLid(client_data, window_size, step_size)\n",
        "    \n",
        "    # Create the client dataset for the current LCLid\n",
        "    preprocessed_client_dataset = preprocess_client_dataset(tf.data.Dataset.from_tensor_slices(clientxx_dataset))\n",
        "    \n",
        "    # Extract a sample batch from the preprocessed dataset\n",
        "    sam_batch = tf.nest.map_structure(lambda x: x.numpy(), next(iter(preprocessed_client_dataset)))\n",
        "    \n",
        "    # Store the preprocessed dataset in the dictionary with LCLid as the key\n",
        "    client_datasets_2013_10[LCLid] = preprocessed_client_dataset"
      ],
      "metadata": {
        "id": "gL9nSC1STQP2"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterate over unique LCLids in the dataframe\n",
        "client_datasets_2013_11 = {}\n",
        "for LCLid in sample_clients_list_2013[10]:\n",
        "    # Filter the dataframe for the current LCLid\n",
        "    client_data = datan_2013[10][datan_2013[10]['LCLid'] == LCLid]\n",
        "\n",
        "    clientxx_dataset = create_client_dataset_for_LCLid(client_data, window_size, step_size)\n",
        "    \n",
        "    # Create the client dataset for the current LCLid\n",
        "    preprocessed_client_dataset = preprocess_client_dataset(tf.data.Dataset.from_tensor_slices(clientxx_dataset))\n",
        "    \n",
        "    # Extract a sample batch from the preprocessed dataset\n",
        "    sam_batch = tf.nest.map_structure(lambda x: x.numpy(), next(iter(preprocessed_client_dataset)))\n",
        "    \n",
        "    # Store the preprocessed dataset in the dictionary with LCLid as the key\n",
        "    client_datasets_2013_11[LCLid] = preprocessed_client_dataset"
      ],
      "metadata": {
        "id": "QkuUMJ8wTQID"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterate over unique LCLids in the dataframe\n",
        "client_datasets_2013_12 = {}\n",
        "for LCLid in sample_clients_list_2013[11]:\n",
        "    # Filter the dataframe for the current LCLid\n",
        "    client_data = datan_2013[11][datan_2013[11]['LCLid'] == LCLid]\n",
        "\n",
        "    clientxx_dataset = create_client_dataset_for_LCLid(client_data, window_size, step_size)\n",
        "    \n",
        "    # Create the client dataset for the current LCLid\n",
        "    preprocessed_client_dataset = preprocess_client_dataset(tf.data.Dataset.from_tensor_slices(clientxx_dataset))\n",
        "    \n",
        "    # Extract a sample batch from the preprocessed dataset\n",
        "    sam_batch = tf.nest.map_structure(lambda x: x.numpy(), next(iter(preprocessed_client_dataset)))\n",
        "    \n",
        "    # Store the preprocessed dataset in the dictionary with LCLid as the key\n",
        "    client_datasets_2013_12[LCLid] = preprocessed_client_dataset"
      ],
      "metadata": {
        "id": "1dc_0hcmTP96"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#client_datasets_2012_6\n",
        "client_datasets_2013_2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "07XAJVQj6hEq",
        "outputId": "6a18e83f-81e3-4330-b312-5503efcbc699"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'MAC000025': <_PrefetchDataset element_spec=OrderedDict([('x', TensorSpec(shape=(None, 336), dtype=tf.float32, name=None)), ('y', TensorSpec(shape=(None, 1), dtype=tf.float32, name=None))])>,\n",
              " 'MAC000104': <_PrefetchDataset element_spec=OrderedDict([('x', TensorSpec(shape=(None, 336), dtype=tf.float32, name=None)), ('y', TensorSpec(shape=(None, 1), dtype=tf.float32, name=None))])>,\n",
              " 'MAC000160': <_PrefetchDataset element_spec=OrderedDict([('x', TensorSpec(shape=(None, 336), dtype=tf.float32, name=None)), ('y', TensorSpec(shape=(None, 1), dtype=tf.float32, name=None))])>,\n",
              " 'MAC000200': <_PrefetchDataset element_spec=OrderedDict([('x', TensorSpec(shape=(None, 336), dtype=tf.float32, name=None)), ('y', TensorSpec(shape=(None, 1), dtype=tf.float32, name=None))])>,\n",
              " 'MAC000229': <_PrefetchDataset element_spec=OrderedDict([('x', TensorSpec(shape=(None, 336), dtype=tf.float32, name=None)), ('y', TensorSpec(shape=(None, 1), dtype=tf.float32, name=None))])>,\n",
              " 'MAC000283': <_PrefetchDataset element_spec=OrderedDict([('x', TensorSpec(shape=(None, 336), dtype=tf.float32, name=None)), ('y', TensorSpec(shape=(None, 1), dtype=tf.float32, name=None))])>,\n",
              " 'MAC000297': <_PrefetchDataset element_spec=OrderedDict([('x', TensorSpec(shape=(None, 336), dtype=tf.float32, name=None)), ('y', TensorSpec(shape=(None, 1), dtype=tf.float32, name=None))])>,\n",
              " 'MAC000318': <_PrefetchDataset element_spec=OrderedDict([('x', TensorSpec(shape=(None, 336), dtype=tf.float32, name=None)), ('y', TensorSpec(shape=(None, 1), dtype=tf.float32, name=None))])>,\n",
              " 'MAC000319': <_PrefetchDataset element_spec=OrderedDict([('x', TensorSpec(shape=(None, 336), dtype=tf.float32, name=None)), ('y', TensorSpec(shape=(None, 1), dtype=tf.float32, name=None))])>,\n",
              " 'MAC000391': <_PrefetchDataset element_spec=OrderedDict([('x', TensorSpec(shape=(None, 336), dtype=tf.float32, name=None)), ('y', TensorSpec(shape=(None, 1), dtype=tf.float32, name=None))])>}"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "client_datasets_2012 = np.array([\n",
        "    client_datasets_2012_1,\n",
        "    client_datasets_2012_2,\n",
        "    client_datasets_2012_3,\n",
        "    client_datasets_2012_4,\n",
        "    client_datasets_2012_5,\n",
        "    client_datasets_2012_6,\n",
        "    client_datasets_2012_7,\n",
        "    client_datasets_2012_8,\n",
        "    client_datasets_2012_9,\n",
        "    client_datasets_2012_10,\n",
        "    client_datasets_2012_11,\n",
        "    client_datasets_2012_12\n",
        "])\n",
        "\n",
        "client_datasets_2013 = np.array([\n",
        "    client_datasets_2013_1,\n",
        "    client_datasets_2013_2,\n",
        "    client_datasets_2013_3,\n",
        "    client_datasets_2013_4,\n",
        "    client_datasets_2013_5,\n",
        "    client_datasets_2013_6,\n",
        "    client_datasets_2013_7,\n",
        "    client_datasets_2013_8,\n",
        "    client_datasets_2013_9,\n",
        "    client_datasets_2013_10,\n",
        "    client_datasets_2013_11,\n",
        "    client_datasets_2013_12\n",
        "])"
      ],
      "metadata": {
        "id": "8UZNW-P26CTt"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_clients_list_2012[5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P4VimBbVIFRI",
        "outputId": "466242a3-2816-4f1f-df93-609b9687e22e"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['MAC000025',\n",
              " 'MAC000104',\n",
              " 'MAC000160',\n",
              " 'MAC000200',\n",
              " 'MAC000229',\n",
              " 'MAC000283',\n",
              " 'MAC000297',\n",
              " 'MAC000318',\n",
              " 'MAC000319',\n",
              " 'MAC000391']"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def make_federated_data(client_datasets, sample_clients_list):\n",
        "    return [\n",
        "        client_datasets[x] for x in sample_clients_list\n",
        "    ]"
      ],
      "metadata": {
        "id": "GsCsqQpoCcLM"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "federated_train_data_2012 = []\n",
        "federated_train_data_2013 = []\n",
        "\n",
        "for i in range(tmfrme):\n",
        "  federated_train_data_2012.append(make_federated_data(client_datasets_2012[i], sample_clients_list_2012[i]))\n",
        "  federated_train_data_2013.append(make_federated_data(client_datasets_2013[i], sample_clients_list_2013[i]))\n",
        "\n",
        "print(f'Number of client datasets: {len(federated_train_data_2012[0])}')\n",
        "print(f'First dataset: {federated_train_data_2012[0][0]}')\n",
        "print(f'Second dataset: {federated_train_data_2012[0][1]}')"
      ],
      "metadata": {
        "id": "Iu7OggamCeEe",
        "outputId": "847ba097-689d-46aa-9d65-84271887602b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of client datasets: 10\n",
            "First dataset: <_PrefetchDataset element_spec=OrderedDict([('x', TensorSpec(shape=(None, 336), dtype=tf.float32, name=None)), ('y', TensorSpec(shape=(None, 1), dtype=tf.float32, name=None))])>\n",
            "Second dataset: <_PrefetchDataset element_spec=OrderedDict([('x', TensorSpec(shape=(None, 336), dtype=tf.float32, name=None)), ('y', TensorSpec(shape=(None, 1), dtype=tf.float32, name=None))])>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessed_example_client_dataset.element_spec"
      ],
      "metadata": {
        "id": "6DdkI_atCgKM",
        "outputId": "415b7bb6-d523-4177-fcab-160c9a93f212",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('x', TensorSpec(shape=(None, 336), dtype=tf.float32, name=None)),\n",
              "             ('y', TensorSpec(shape=(None, 1), dtype=tf.float32, name=None))])"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model():\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Dense(64, activation='relu', input_shape=(336,)),\n",
        "        tf.keras.layers.Dense(32, activation='relu'),\n",
        "        tf.keras.layers.Dense(1)\n",
        "    ])\n",
        "    return model"
      ],
      "metadata": {
        "id": "6rUbnZGaCiVq"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model_fn():\n",
        "    keras_model = create_model()\n",
        "    loss = tf.keras.losses.MeanSquaredError() \n",
        "    tff_model = tff.learning.models.from_keras_model(\n",
        "        keras_model,\n",
        "        input_spec=preprocessed_example_client_dataset.element_spec,\n",
        "        loss=loss,\n",
        "        metrics=[tf.keras.metrics.MeanAbsoluteError()]\n",
        "    )\n",
        "    return tff_model"
      ],
      "metadata": {
        "id": "4Di8FeyRCkP6"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = model_fn()\n",
        "print(model)"
      ],
      "metadata": {
        "id": "uYTmkmymCl_F",
        "outputId": "45c53851-b6ee-4c4b-d808-46b750dd3007",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<tensorflow_federated.python.learning.models.keras_utils._KerasModel object at 0x7fd1054fc430>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# training starts\n",
        "training_process = tff.learning.algorithms.build_weighted_fed_avg(\n",
        "    model_fn,\n",
        "    client_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=0.02),\n",
        "    server_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=1.0))"
      ],
      "metadata": {
        "id": "kjGkDl_5Cn4u"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(training_process.initialize.type_signature.formatted_representation())"
      ],
      "metadata": {
        "id": "aWySzL0ICqzz",
        "outputId": "cccb1409-f036-49b7-aa90-3921c39a0d8f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "( -> <\n",
            "  global_model_weights=<\n",
            "    trainable=<\n",
            "      float32[336,64],\n",
            "      float32[64],\n",
            "      float32[64,32],\n",
            "      float32[32],\n",
            "      float32[32,1],\n",
            "      float32[1]\n",
            "    >,\n",
            "    non_trainable=<>\n",
            "  >,\n",
            "  distributor=<>,\n",
            "  client_work=<>,\n",
            "  aggregator=<\n",
            "    value_sum_process=<>,\n",
            "    weight_sum_process=<>\n",
            "  >,\n",
            "  finalizer=<\n",
            "    int64,\n",
            "    float32[336,64],\n",
            "    float32[64],\n",
            "    float32[64,32],\n",
            "    float32[32],\n",
            "    float32[32,1],\n",
            "    float32[1]\n",
            "  >\n",
            ">@SERVER)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_state = training_process.initialize()"
      ],
      "metadata": {
        "id": "MOQh3Uy8CtS8"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "federated_train_data_2012[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I_ctGCU1M9U9",
        "outputId": "b5294642-0360-4b11-b445-18fbeb4b2bb3"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<_PrefetchDataset element_spec=OrderedDict([('x', TensorSpec(shape=(None, 336), dtype=tf.float32, name=None)), ('y', TensorSpec(shape=(None, 1), dtype=tf.float32, name=None))])>,\n",
              " <_PrefetchDataset element_spec=OrderedDict([('x', TensorSpec(shape=(None, 336), dtype=tf.float32, name=None)), ('y', TensorSpec(shape=(None, 1), dtype=tf.float32, name=None))])>,\n",
              " <_PrefetchDataset element_spec=OrderedDict([('x', TensorSpec(shape=(None, 336), dtype=tf.float32, name=None)), ('y', TensorSpec(shape=(None, 1), dtype=tf.float32, name=None))])>,\n",
              " <_PrefetchDataset element_spec=OrderedDict([('x', TensorSpec(shape=(None, 336), dtype=tf.float32, name=None)), ('y', TensorSpec(shape=(None, 1), dtype=tf.float32, name=None))])>,\n",
              " <_PrefetchDataset element_spec=OrderedDict([('x', TensorSpec(shape=(None, 336), dtype=tf.float32, name=None)), ('y', TensorSpec(shape=(None, 1), dtype=tf.float32, name=None))])>,\n",
              " <_PrefetchDataset element_spec=OrderedDict([('x', TensorSpec(shape=(None, 336), dtype=tf.float32, name=None)), ('y', TensorSpec(shape=(None, 1), dtype=tf.float32, name=None))])>,\n",
              " <_PrefetchDataset element_spec=OrderedDict([('x', TensorSpec(shape=(None, 336), dtype=tf.float32, name=None)), ('y', TensorSpec(shape=(None, 1), dtype=tf.float32, name=None))])>,\n",
              " <_PrefetchDataset element_spec=OrderedDict([('x', TensorSpec(shape=(None, 336), dtype=tf.float32, name=None)), ('y', TensorSpec(shape=(None, 1), dtype=tf.float32, name=None))])>,\n",
              " <_PrefetchDataset element_spec=OrderedDict([('x', TensorSpec(shape=(None, 336), dtype=tf.float32, name=None)), ('y', TensorSpec(shape=(None, 1), dtype=tf.float32, name=None))])>,\n",
              " <_PrefetchDataset element_spec=OrderedDict([('x', TensorSpec(shape=(None, 336), dtype=tf.float32, name=None)), ('y', TensorSpec(shape=(None, 1), dtype=tf.float32, name=None))])>]"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "federated_train_data_2013[6]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gyFQFAIrNBXK",
        "outputId": "f355eb85-f7de-40cf-bc0f-865b6856b2f4"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<_PrefetchDataset element_spec=OrderedDict([('x', TensorSpec(shape=(None, 336), dtype=tf.float32, name=None)), ('y', TensorSpec(shape=(None, 1), dtype=tf.float32, name=None))])>,\n",
              " <_PrefetchDataset element_spec=OrderedDict([('x', TensorSpec(shape=(None, 336), dtype=tf.float32, name=None)), ('y', TensorSpec(shape=(None, 1), dtype=tf.float32, name=None))])>,\n",
              " <_PrefetchDataset element_spec=OrderedDict([('x', TensorSpec(shape=(None, 336), dtype=tf.float32, name=None)), ('y', TensorSpec(shape=(None, 1), dtype=tf.float32, name=None))])>,\n",
              " <_PrefetchDataset element_spec=OrderedDict([('x', TensorSpec(shape=(None, 336), dtype=tf.float32, name=None)), ('y', TensorSpec(shape=(None, 1), dtype=tf.float32, name=None))])>,\n",
              " <_PrefetchDataset element_spec=OrderedDict([('x', TensorSpec(shape=(None, 336), dtype=tf.float32, name=None)), ('y', TensorSpec(shape=(None, 1), dtype=tf.float32, name=None))])>,\n",
              " <_PrefetchDataset element_spec=OrderedDict([('x', TensorSpec(shape=(None, 336), dtype=tf.float32, name=None)), ('y', TensorSpec(shape=(None, 1), dtype=tf.float32, name=None))])>,\n",
              " <_PrefetchDataset element_spec=OrderedDict([('x', TensorSpec(shape=(None, 336), dtype=tf.float32, name=None)), ('y', TensorSpec(shape=(None, 1), dtype=tf.float32, name=None))])>,\n",
              " <_PrefetchDataset element_spec=OrderedDict([('x', TensorSpec(shape=(None, 336), dtype=tf.float32, name=None)), ('y', TensorSpec(shape=(None, 1), dtype=tf.float32, name=None))])>,\n",
              " <_PrefetchDataset element_spec=OrderedDict([('x', TensorSpec(shape=(None, 336), dtype=tf.float32, name=None)), ('y', TensorSpec(shape=(None, 1), dtype=tf.float32, name=None))])>,\n",
              " <_PrefetchDataset element_spec=OrderedDict([('x', TensorSpec(shape=(None, 336), dtype=tf.float32, name=None)), ('y', TensorSpec(shape=(None, 1), dtype=tf.float32, name=None))])>]"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_ROUNDS = 12\n",
        "for round_num in range(1, NUM_ROUNDS+1):\n",
        "  result = training_process.next(train_state, federated_train_data_2012[round_num-1])\n",
        "  train_state = result.state\n",
        "  train_metrics = result.metrics\n",
        "  print('round {:2d}, metrics={}'.format(round_num, train_metrics))"
      ],
      "metadata": {
        "id": "Q_aepcl_C03R",
        "outputId": "c8a40251-b508-4594-ac92-47411a589b10",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "round  1, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('mean_absolute_error', 0.099647164), ('loss', 0.03408825), ('num_examples', 55300), ('num_batches', 2770)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "round  2, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('mean_absolute_error', 0.09152479), ('loss', 0.029405337), ('num_examples', 50485), ('num_batches', 2530)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "round  3, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('mean_absolute_error', 0.10100907), ('loss', 0.03482601), ('num_examples', 49165), ('num_batches', 2463)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "round  4, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('mean_absolute_error', 0.08574918), ('loss', 0.029879978), ('num_examples', 52850), ('num_batches', 2647)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "round  5, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('mean_absolute_error', 0.078378655), ('loss', 0.023830293), ('num_examples', 55265), ('num_batches', 2768)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "round  6, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('mean_absolute_error', 0.0747076), ('loss', 0.023033572), ('num_examples', 52890), ('num_batches', 2650)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "round  7, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('mean_absolute_error', 0.07270582), ('loss', 0.02074937), ('num_examples', 55295), ('num_batches', 2770)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "round  8, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('mean_absolute_error', 0.06436126), ('loss', 0.016228996), ('num_examples', 55275), ('num_batches', 2769)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "round  9, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('mean_absolute_error', 0.058367517), ('loss', 0.012776308), ('num_examples', 52895), ('num_batches', 2650)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "round 10, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('mean_absolute_error', 0.08243488), ('loss', 0.024023509), ('num_examples', 55290), ('num_batches', 2770)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "round 11, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('mean_absolute_error', 0.096186414), ('loss', 0.031486686), ('num_examples', 55295), ('num_batches', 2770)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "round 12, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('mean_absolute_error', 0.094861075), ('loss', 0.03073404), ('num_examples', 55295), ('num_batches', 2770)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "EVALUATION"
      ],
      "metadata": {
        "id": "li3jMaI7dKVi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter the DataFrame to include readings from Jan 01, 2014, to Jan 31, 2014\n",
        "teststart_date = pd.to_datetime('2014-01-01')\n",
        "testend_date = pd.to_datetime('2014-01-31')\n",
        "test_data = data[(data['DateTime'] >= start_date1) & (data['DateTime'] <= end_date1)]"
      ],
      "metadata": {
        "id": "Ep7pZEumcHBI"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select 5 unique LCLids\n",
        "lclid_lt = test_data['LCLid'].unique()\n",
        "sel_lclids = lclid_lt[:1]\n",
        "\n",
        "# Filter data for the selected LCLids\n",
        "ft_data = test_data[test_data['LCLid'].isin(sel_lclids)]"
      ],
      "metadata": {
        "id": "_O4OJjoMcSuu"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ft_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "fIUog6XPdsmI",
        "outputId": "8abb3165-aa5c-487c-a1b0-7eb93a4c53f5"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          LCLid stdorToU            DateTime  KWH/hh  cluster\n",
              "1179  MAC000025      Std 2012-01-01 00:00:00   0.056       14\n",
              "1180  MAC000025      Std 2012-01-01 00:30:00   0.020       14\n",
              "1181  MAC000025      Std 2012-01-01 01:00:00   0.017       14\n",
              "1182  MAC000025      Std 2012-01-01 01:30:00   0.000       14\n",
              "1183  MAC000025      Std 2012-01-01 02:00:00   0.023       14\n",
              "...         ...      ...                 ...     ...      ...\n",
              "2616  MAC000025      Std 2012-01-30 22:00:00   0.023       14\n",
              "2617  MAC000025      Std 2012-01-30 22:30:00   0.002       14\n",
              "2618  MAC000025      Std 2012-01-30 23:00:00   0.004       14\n",
              "2619  MAC000025      Std 2012-01-30 23:30:00   0.019       14\n",
              "2620  MAC000025      Std 2012-01-31 00:00:00   0.000       14\n",
              "\n",
              "[1442 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e67d119c-56bb-4e0b-91c9-dce3fa32cfd1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>LCLid</th>\n",
              "      <th>stdorToU</th>\n",
              "      <th>DateTime</th>\n",
              "      <th>KWH/hh</th>\n",
              "      <th>cluster</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1179</th>\n",
              "      <td>MAC000025</td>\n",
              "      <td>Std</td>\n",
              "      <td>2012-01-01 00:00:00</td>\n",
              "      <td>0.056</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1180</th>\n",
              "      <td>MAC000025</td>\n",
              "      <td>Std</td>\n",
              "      <td>2012-01-01 00:30:00</td>\n",
              "      <td>0.020</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1181</th>\n",
              "      <td>MAC000025</td>\n",
              "      <td>Std</td>\n",
              "      <td>2012-01-01 01:00:00</td>\n",
              "      <td>0.017</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1182</th>\n",
              "      <td>MAC000025</td>\n",
              "      <td>Std</td>\n",
              "      <td>2012-01-01 01:30:00</td>\n",
              "      <td>0.000</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1183</th>\n",
              "      <td>MAC000025</td>\n",
              "      <td>Std</td>\n",
              "      <td>2012-01-01 02:00:00</td>\n",
              "      <td>0.023</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2616</th>\n",
              "      <td>MAC000025</td>\n",
              "      <td>Std</td>\n",
              "      <td>2012-01-30 22:00:00</td>\n",
              "      <td>0.023</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2617</th>\n",
              "      <td>MAC000025</td>\n",
              "      <td>Std</td>\n",
              "      <td>2012-01-30 22:30:00</td>\n",
              "      <td>0.002</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2618</th>\n",
              "      <td>MAC000025</td>\n",
              "      <td>Std</td>\n",
              "      <td>2012-01-30 23:00:00</td>\n",
              "      <td>0.004</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2619</th>\n",
              "      <td>MAC000025</td>\n",
              "      <td>Std</td>\n",
              "      <td>2012-01-30 23:30:00</td>\n",
              "      <td>0.019</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2620</th>\n",
              "      <td>MAC000025</td>\n",
              "      <td>Std</td>\n",
              "      <td>2012-01-31 00:00:00</td>\n",
              "      <td>0.000</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1442 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e67d119c-56bb-4e0b-91c9-dce3fa32cfd1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e67d119c-56bb-4e0b-91c9-dce3fa32cfd1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e67d119c-56bb-4e0b-91c9-dce3fa32cfd1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ft_data['KWH/hh'] = ft_data['KWH/hh'].astype(np.float32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gi4h2J5Ido7W",
        "outputId": "1f609600-d43c-4d93-d1c1-a753c97e2903"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-88-398836f43ad2>:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  ft_data['KWH/hh'] = ft_data['KWH/hh'].astype(np.float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ft_data = ft_data.drop('cluster', axis=1)\n",
        "ft_data = ft_data.drop('stdorToU', axis=1)\n",
        "ft_data.reset_index(drop=True, inplace=True)"
      ],
      "metadata": {
        "id": "JfoJGu9ado46"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ft_data['DateTime'] = pd.to_datetime(ft_data.DateTime).dt.tz_localize(None)\n",
        "for i in range(len(ft_data)):\n",
        "  ft_data['DateTime'][i]=ft_data['DateTime'][i].timestamp()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W_b9yivedo2e",
        "outputId": "b83854a1-e4dd-4ac2-d8ec-262b89a0a45b"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-90-fe80fcc7ed1b>:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  ft_data['DateTime'][i]=ft_data['DateTime'][i].timestamp()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ft_data['DateTime'] = ft_data['DateTime'].astype(np.float32)"
      ],
      "metadata": {
        "id": "kEUJMICBdowu"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sort the data by 'LCLid' and 'DateTime'\n",
        "ft_data.sort_values(['LCLid', 'DateTime'], inplace=True)"
      ],
      "metadata": {
        "id": "8xwPUC4zdot-"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_client = ft_data['LCLid'].unique()[0:1]\n",
        "test_client "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yaItYVw_dore",
        "outputId": "f09a3cef-feed-4d17-e23c-9e3c0f5b2eb2"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['MAC000025'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = {}\n",
        "\n",
        "for LCLid in test_client:\n",
        "    # Filter the dataframe for the current LCLid\n",
        "    client_data = ft_data[ft_data['LCLid'] == LCLid]\n",
        "\n",
        "    clientxx_dataset = create_client_dataset_for_LCLid(client_data, window_size, step_size)\n",
        "    \n",
        "    # Create the client dataset for the current LCLid\n",
        "    preprocessed_client_dataset = preprocess_client_dataset(tf.data.Dataset.from_tensor_slices(clientxx_dataset))\n",
        "    \n",
        "    # Extract a sample batch from the preprocessed dataset\n",
        "    sam_batch = tf.nest.map_structure(lambda x: x.numpy(), next(iter(preprocessed_client_dataset)))\n",
        "    \n",
        "    # Store the preprocessed dataset in the dictionary with LCLid as the key\n",
        "    test_dataset[LCLid] = preprocessed_client_dataset\n",
        "\n",
        "    print(\"Client dataset for LCLid\", LCLid)\n",
        "    print(sam_batch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LKpzGB8ldoov",
        "outputId": "85164ccf-50fe-4755-f9b8-76a7dc378171"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Client dataset for LCLid MAC000025\n",
            "OrderedDict([('x', array([[0.007, 0.   , 0.019, ..., 0.001, 0.002, 0.022],\n",
            "       [0.   , 0.026, 0.19 , ..., 0.009, 0.   , 0.022],\n",
            "       [0.024, 0.   , 0.01 , ..., 0.   , 0.023, 0.002],\n",
            "       ...,\n",
            "       [0.043, 0.628, 0.028, ..., 0.015, 0.126, 0.119],\n",
            "       [0.045, 0.016, 0.   , ..., 0.001, 0.   , 0.153],\n",
            "       [0.689, 0.631, 0.016, ..., 0.023, 0.126, 0.077]], dtype=float32)), ('y', array([[0.   ],\n",
            "       [0.001],\n",
            "       [0.016],\n",
            "       [0.032],\n",
            "       [0.   ],\n",
            "       [0.022],\n",
            "       [0.058],\n",
            "       [0.016],\n",
            "       [0.024],\n",
            "       [0.598],\n",
            "       [0.119],\n",
            "       [0.023],\n",
            "       [0.023],\n",
            "       [0.013],\n",
            "       [0.072],\n",
            "       [0.037],\n",
            "       [0.005],\n",
            "       [0.64 ],\n",
            "       [0.057],\n",
            "       [0.74 ]], dtype=float32))])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make federated test data\n",
        "federated_test_data = make_federated_data(test_dataset, test_client)"
      ],
      "metadata": {
        "id": "ejwHEV7dfNRi"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluation_process = tff.learning.algorithms.build_fed_eval(model_fn)"
      ],
      "metadata": {
        "id": "jsXCPlt_dMaE"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(evaluation_process.next.type_signature.formatted_representation())"
      ],
      "metadata": {
        "id": "MKElSjxsdOjJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a82b3e81-3bfe-4bbd-93c4-563cc6050a7e"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(<\n",
            "  state=<\n",
            "    global_model_weights=<\n",
            "      trainable=<\n",
            "        float32[336,64],\n",
            "        float32[64],\n",
            "        float32[64,32],\n",
            "        float32[32],\n",
            "        float32[32,1],\n",
            "        float32[1]\n",
            "      >,\n",
            "      non_trainable=<>\n",
            "    >,\n",
            "    distributor=<>,\n",
            "    client_work=<\n",
            "      <>,\n",
            "      <\n",
            "        mean_absolute_error=<\n",
            "          float32,\n",
            "          float32\n",
            "        >,\n",
            "        loss=<\n",
            "          float32,\n",
            "          float32\n",
            "        >,\n",
            "        num_examples=<\n",
            "          int64\n",
            "        >,\n",
            "        num_batches=<\n",
            "          int64\n",
            "        >\n",
            "      >\n",
            "    >,\n",
            "    aggregator=<\n",
            "      value_sum_process=<>,\n",
            "      weight_sum_process=<>\n",
            "    >,\n",
            "    finalizer=<>\n",
            "  >@SERVER,\n",
            "  client_data={<\n",
            "    x=float32[?,336],\n",
            "    y=float32[?,1]\n",
            "  >*}@CLIENTS\n",
            "> -> <\n",
            "  state=<\n",
            "    global_model_weights=<\n",
            "      trainable=<\n",
            "        float32[336,64],\n",
            "        float32[64],\n",
            "        float32[64,32],\n",
            "        float32[32],\n",
            "        float32[32,1],\n",
            "        float32[1]\n",
            "      >,\n",
            "      non_trainable=<>\n",
            "    >,\n",
            "    distributor=<>,\n",
            "    client_work=<\n",
            "      <>,\n",
            "      <\n",
            "        mean_absolute_error=<\n",
            "          float32,\n",
            "          float32\n",
            "        >,\n",
            "        loss=<\n",
            "          float32,\n",
            "          float32\n",
            "        >,\n",
            "        num_examples=<\n",
            "          int64\n",
            "        >,\n",
            "        num_batches=<\n",
            "          int64\n",
            "        >\n",
            "      >\n",
            "    >,\n",
            "    aggregator=<\n",
            "      value_sum_process=<>,\n",
            "      weight_sum_process=<>\n",
            "    >,\n",
            "    finalizer=<>\n",
            "  >@SERVER,\n",
            "  metrics=<\n",
            "    distributor=<>,\n",
            "    client_work=<\n",
            "      eval=<\n",
            "        current_round_metrics=<\n",
            "          mean_absolute_error=float32,\n",
            "          loss=float32,\n",
            "          num_examples=int64,\n",
            "          num_batches=int64\n",
            "        >,\n",
            "        total_rounds_metrics=<\n",
            "          mean_absolute_error=float32,\n",
            "          loss=float32,\n",
            "          num_examples=int64,\n",
            "          num_batches=int64\n",
            "        >\n",
            "      >\n",
            "    >,\n",
            "    aggregator=<\n",
            "      mean_value=<>,\n",
            "      mean_weight=<>\n",
            "    >,\n",
            "    finalizer=<>\n",
            "  >@SERVER\n",
            ">)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluation_state = evaluation_process.initialize()\n",
        "model_weights = training_process.get_model_weights(train_state)\n",
        "evaluation_state = evaluation_process.set_model_weights(evaluation_state, model_weights)"
      ],
      "metadata": {
        "id": "dUTjxtW3dZRq"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluation_output = evaluation_process.next(evaluation_state, federated_test_data)"
      ],
      "metadata": {
        "id": "krNJ9-l8daTC"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "str(evaluation_output.metrics)"
      ],
      "metadata": {
        "id": "OekeO539dmfI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "733fc692-d37e-411f-94e1-f0124305cc00"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"OrderedDict([('distributor', ()), ('client_work', OrderedDict([('eval', OrderedDict([('current_round_metrics', OrderedDict([('mean_absolute_error', 0.16563305), ('loss', 0.074171424), ('num_examples', 5530), ('num_batches', 277)])), ('total_rounds_metrics', OrderedDict([('mean_absolute_error', 0.16563305), ('loss', 0.074171424), ('num_examples', 5530), ('num_batches', 277)]))]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', ())])\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Training again foranother 12 months and testing the loss"
      ],
      "metadata": {
        "id": "_QaHvuUAf6DY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_ROUNDS = 12\n",
        "for round_num in range(1, NUM_ROUNDS+1):\n",
        "  result = training_process.next(train_state, federated_train_data_2013[round_num-1])\n",
        "  train_state = result.state\n",
        "  train_metrics = result.metrics\n",
        "  print('round {:2d}, metrics={}'.format(round_num, train_metrics))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OrjKszJXf-JN",
        "outputId": "9934dd23-544c-4382-f31a-70797d992701"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "round  1, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('mean_absolute_error', 0.11018429), ('loss', 0.038093057), ('num_examples', 55250), ('num_batches', 2767)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "round  2, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('mean_absolute_error', 0.09519737), ('loss', 0.02932922), ('num_examples', 48070), ('num_batches', 2407)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "round  3, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('mean_absolute_error', 0.08842387), ('loss', 0.028131777), ('num_examples', 55300), ('num_batches', 2770)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "round  4, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('mean_absolute_error', 0.08153795), ('loss', 0.024461899), ('num_examples', 52885), ('num_batches', 2650)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "round  5, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('mean_absolute_error', 0.077494405), ('loss', 0.022295833), ('num_examples', 55280), ('num_batches', 2769)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "round  6, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('mean_absolute_error', 0.06430122), ('loss', 0.01566607), ('num_examples', 52890), ('num_batches', 2649)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "round  7, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('mean_absolute_error', 0.05229401), ('loss', 0.010851788), ('num_examples', 55285), ('num_batches', 2770)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "round  8, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('mean_absolute_error', 0.056900874), ('loss', 0.01184202), ('num_examples', 55225), ('num_batches', 2766)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "round  9, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('mean_absolute_error', 0.07928919), ('loss', 0.025932927), ('num_examples', 52880), ('num_batches', 2650)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "round 10, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('mean_absolute_error', 0.095914684), ('loss', 0.032544922), ('num_examples', 55290), ('num_batches', 2770)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "round 11, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('mean_absolute_error', 0.097309954), ('loss', 0.03555725), ('num_examples', 52890), ('num_batches', 2650)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "round 12, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('mean_absolute_error', 0.10038524), ('loss', 0.036801647), ('num_examples', 55290), ('num_batches', 2770)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing the same test dataset to check the loss"
      ],
      "metadata": {
        "id": "XkLQe0pph6uG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "evaluation_process2 = tff.learning.algorithms.build_fed_eval(model_fn)"
      ],
      "metadata": {
        "id": "lwdbvMbnf_nL"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluation_state2 = evaluation_process2.initialize()\n",
        "model_weights2 = training_process.get_model_weights(train_state)\n",
        "evaluation_state2 = evaluation_process2.set_model_weights(evaluation_state2, model_weights)"
      ],
      "metadata": {
        "id": "8LSZfVRYiHms"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluation_output2 = evaluation_process2.next(evaluation_state2, federated_test_data)"
      ],
      "metadata": {
        "id": "jsEO-ECJiUxz"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "str(evaluation_output2.metrics)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "FS0MQDHciX1N",
        "outputId": "7c63ce3a-9185-4ec0-82f8-ec45eb08f147"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"OrderedDict([('distributor', ()), ('client_work', OrderedDict([('eval', OrderedDict([('current_round_metrics', OrderedDict([('mean_absolute_error', 0.16563308), ('loss', 0.074171394), ('num_examples', 5530), ('num_batches', 277)])), ('total_rounds_metrics', OrderedDict([('mean_absolute_error', 0.16563308), ('loss', 0.074171394), ('num_examples', 5530), ('num_batches', 277)]))]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', ())])\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "str(evaluation_output.metrics)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "NQPROd0Zi0gy",
        "outputId": "efd9e0c6-8bee-47ac-a34a-d34a3b55b071"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"OrderedDict([('distributor', ()), ('client_work', OrderedDict([('eval', OrderedDict([('current_round_metrics', OrderedDict([('mean_absolute_error', 0.16563305), ('loss', 0.074171424), ('num_examples', 5530), ('num_batches', 277)])), ('total_rounds_metrics', OrderedDict([('mean_absolute_error', 0.16563305), ('loss', 0.074171424), ('num_examples', 5530), ('num_batches', 277)]))]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', ())])\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}